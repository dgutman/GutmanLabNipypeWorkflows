{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype\n",
    "import os,glob,sys,shutil\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.interfaces.io as nio\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899 Subjects are potentially available to be processed!\n"
     ]
    }
   ],
   "source": [
    "subjRootDir = \"/data/HCP_Data/HCP_BedpostData/\"\n",
    "FULL_SUBJECT_LIST = [x for x in os.listdir(subjRootDir) if os.path.isdir( subjRootDir+x)]\n",
    "print(len(FULL_SUBJECT_LIST),\"Subjects are potentially available to be processed!\")\n",
    "SampleSubjList = ['329440']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup for Probtrackx2 Computational Pipeline\n",
    "\"\"\"\n",
    "subj_infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),  name=\"subj_infosource\")\n",
    "#infosource.iterables = ('subject_id', SampleSubjList)\n",
    "subj_infosource.iterables = ('subject_id', FULL_SUBJECT_LIST[0:2])\n",
    "### Above just converts the list of subjects into an iterable list I can connect to the next part of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Setup for DataGrabber inputs needed for probtrackx2\n",
    "# \"\"\"\n",
    "datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "        outfields=['nodif_brain_mask','xfm','invxfm','thsamples','phsamples','fsamples']),\n",
    "        name='datasource')\n",
    "# create a node to obtain the functional images\n",
    "datasource.inputs.base_directory = \"/data/HCP_Data/HCP_BedpostData/\"\n",
    "datasource.inputs.template ='*'\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.field_template = dict(\n",
    "    thsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    fsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    phsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    nodif_brain_mask='%s/T1w/Diffusion.bedpostX/%s.nii*', \n",
    "    xfm='%s/MNINonLinear/xfms/%s.nii*',\n",
    "    invxfm='%s/MNINonLinear/xfms/%s.nii*'\n",
    "    )\n",
    "\n",
    "datasource.inputs.template_args = dict(\n",
    "             thsamples = [['subject_id','th1samples']],\n",
    "             phsamples =  [['subject_id','ph1samples']],\n",
    "             fsamples =  [['subject_id','f1samples']],\n",
    "             nodif_brain_mask = [['subject_id','nodif_brain_mask']],\n",
    "             xfm = [['subject_id','acpc_dc2standard']],\n",
    "             invxfm = [['subject_id', 'standard2acpc_dc']]           \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seedMask = \"/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Bilat.nii.gz\"\n",
    "seedMaskList = glob.glob('/data/HCP_Data/EHECHT_ROIS/Hu*')\n",
    "debug_output = False\n",
    "\n",
    "\n",
    "if debug_output:\n",
    "    pbx2 = fsl.ProbTrackX2()\n",
    "    pbx2.inputs.thsamples=subjRootDir+SampleSubjList[0]+'/T1w/Diffusion.bedpostX/merged_th1samples.nii.gz'\n",
    "    pbx2.inputs.phsamples=subjRootDir+SampleSubjList[0]+'/T1w/Diffusion.bedpostX/merged_ph1samples.nii.gz'\n",
    "    pbx2.inputs.fsamples=subjRootDir+SampleSubjList[0]+'/T1w/Diffusion.bedpostX/merged_f1samples.nii.gz'\n",
    "    pbx2.inputs.mask = subjRootDir+SampleSubjList[0]+'/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz'\n",
    "    pbx2.inputs.samples_base_name = subjRootDir+SampleSubjList[0]+'/T1w/Diffusion.bedpostX/merged'\n",
    "else:\n",
    "    pbx2 = pe.Node(interface=fsl.ProbTrackX2(), name='pbx2')\n",
    "\n",
    "    \n",
    "pbx2.inputs.c_thresh = 0.2   # -c 0.2   F cutoff\n",
    "pbx2.inputs.n_steps = 2000   # -S 2000\n",
    "pbx2.inputs.step_length = 0.5 # --steplength=0.5\n",
    "pbx2.inputs.n_samples = 50 # -P 5000\n",
    "pbx2.inputs.opd = True\n",
    "pbx2.inputs.loop_check = True\n",
    "# pbx2.inputs.fibst = True\n",
    "\n",
    "\n",
    "pbx2.iterables = (\"seed\", seedMaskList)\n",
    "\n",
    "## fibthresh\n",
    "# pbx2.inputs.onewaycondition = True # --onewaycondition\n",
    "pbx2.inputs.correct_path_distribution = True # -pd  i.e. distance correction\n",
    "#pbx2.inputs.samples_base_name = 'merged'\n",
    "#pbx2.inputs.lrtarget3= targetMask  ## This is a hack for now\n",
    "pbx2.inputs.seed = seedMask\n",
    "#pbx2.inputs.omatrix3 = True   # --omatrix3\n",
    "#pbx2.inputs.target3 = targetMask # --target3=$WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_GM.nii.gz \"; \n",
    "\n",
    "\n",
    "### #FIBTHRESH APPEARS MISSING FROM INTERFACE???\n",
    "\n",
    "if debug_output:\n",
    "    print( pbx2.cmdline)\n",
    "    print(\"WE WILL BE PROCESSING THE FOLLOWING ROIS\")\n",
    "    print([os.path.basename(x) for x in seedMaskList])\n",
    "    pbx2.inputs.os2t = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probtrackx2  --fibthresh=0.1 --randfib=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180711-20:37:15,592 workflow INFO:\n",
      "\t Workflow runpbx2 settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "180711-20:37:15,624 workflow INFO:\n",
      "\t Running serially.\n",
      "180711-20:37:15,625 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.datasource\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/datasource\".\n",
      "180711-20:37:15,640 workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "180711-20:37:15,660 workflow INFO:\n",
      "\t [Node] Finished \"runpbx2.datasource\".\n",
      "180711-20:37:15,663 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2\".\n",
      "180711-20:37:15,685 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Right.nii.gz --steplength=0.500\n",
      "180711-20:37:15,734 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:15.734409:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:15,813 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2)\n",
      "180711-20:37:15,818 workflow ERROR:\n",
      "\t Node pbx2.aI.a5.b1 failed to run on host 145e230a3f42.\n",
      "180711-20:37:15,821 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203715-neuro-pbx2.aI.a5.b1-a8c0a7c7-5907-4813-aa26-c4e6e37f9a57.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Right.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:15,826 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2\".\n",
      "180711-20:37:15,843 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Left.nii.gz --steplength=0.500\n",
      "180711-20:37:15,876 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:15.876036:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:15,973 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2)\n",
      "180711-20:37:15,978 workflow ERROR:\n",
      "\t Node pbx2.aI.a4.b1 failed to run on host 145e230a3f42.\n",
      "180711-20:37:15,981 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203715-neuro-pbx2.aI.a4.b1-5e5c5b76-e3f9-4fca-a91f-ba3f7faa8df7.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Left.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:15,985 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2\".\n",
      "180711-20:37:16,0 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Bilat.nii.gz --steplength=0.500\n",
      "180711-20:37:16,44 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.043972:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180711-20:37:16,120 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2)\n",
      "180711-20:37:16,125 workflow ERROR:\n",
      "\t Node pbx2.aI.a3.b1 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,128 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a3.b1-ef5cf9ce-351e-49d6-b151-8ac2bc90a438.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Bilat.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:16,133 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2\".\n",
      "180711-20:37:16,151 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Right.nii.gz --steplength=0.500\n",
      "180711-20:37:16,184 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.184084:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:16,261 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2)\n",
      "180711-20:37:16,265 workflow ERROR:\n",
      "\t Node pbx2.aI.a2.b1 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,268 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a2.b1-308c9aa9-dca1-4ea4-a91a-18e364274250.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Right.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:16,273 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2\".\n",
      "180711-20:37:16,289 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Left.nii.gz --steplength=0.500\n",
      "180711-20:37:16,325 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.324859:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:16,400 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2)\n",
      "180711-20:37:16,405 workflow ERROR:\n",
      "\t Node pbx2.aI.a1.b1 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,408 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a1.b1-b8af7f4e-416b-413a-8c45-3053094c9edb.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Left.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180711-20:37:16,413 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2\".\n",
      "180711-20:37:16,430 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Bilat.nii.gz --steplength=0.500\n",
      "180711-20:37:16,464 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.464084:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:16,539 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2)\n",
      "180711-20:37:16,544 workflow ERROR:\n",
      "\t Node pbx2.aI.a0.b1 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,546 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a0.b1-2491c217-5a68-4bb4-a9c4-c27199c19ed5.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100307/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100307/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Bilat.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:16,550 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.datasource\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/datasource\".\n",
      "180711-20:37:16,563 workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "180711-20:37:16,576 workflow INFO:\n",
      "\t [Node] Finished \"runpbx2.datasource\".\n",
      "180711-20:37:16,578 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2\".\n",
      "180711-20:37:16,598 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Right.nii.gz --steplength=0.500\n",
      "180711-20:37:16,634 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.634125:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:16,710 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2)\n",
      "180711-20:37:16,715 workflow ERROR:\n",
      "\t Node pbx2.aI.a5.b0 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,717 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a5.b0-9a2ba8d9-2362-41f2-8ae8-bd2f74ce5255.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Right.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:16,723 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2\".\n",
      "180711-20:37:16,739 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Left.nii.gz --steplength=0.500\n",
      "180711-20:37:16,773 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.773702:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:16,850 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180711-20:37:16,855 workflow ERROR:\n",
      "\t Node pbx2.aI.a4.b0 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,857 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a4.b0-33b5ab5d-9942-4975-9489-cedf79f16a63.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Left.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:16,862 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2\".\n",
      "180711-20:37:16,880 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Bilat.nii.gz --steplength=0.500\n",
      "180711-20:37:16,914 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:16.914669:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:16,990 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2)\n",
      "180711-20:37:16,996 workflow ERROR:\n",
      "\t Node pbx2.aI.a3.b0 failed to run on host 145e230a3f42.\n",
      "180711-20:37:16,999 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a3.b0-c734999e-4112-4ee0-ac8d-babe8965a44b.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Bilat.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:17,4 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2\".\n",
      "180711-20:37:17,23 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Right.nii.gz --steplength=0.500\n",
      "180711-20:37:17,57 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:17.057394:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:17,130 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2)\n",
      "180711-20:37:17,134 workflow ERROR:\n",
      "\t Node pbx2.aI.a2.b0 failed to run on host 145e230a3f42.\n",
      "180711-20:37:17,137 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203717-neuro-pbx2.aI.a2.b0-613e098b-05b1-4f1d-bff1-bf6f9ffb1ce7.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Right.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Right.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180711-20:37:17,141 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2\".\n",
      "180711-20:37:17,158 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Left.nii.gz --steplength=0.500\n",
      "180711-20:37:17,194 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:17.193910:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:17,270 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2)\n",
      "180711-20:37:17,275 workflow ERROR:\n",
      "\t Node pbx2.aI.a1.b0 failed to run on host 145e230a3f42.\n",
      "180711-20:37:17,277 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203717-neuro-pbx2.aI.a1.b0-623abcb1-fa0f-49c0-8e41-4d99d0b055ba.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Left.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Left.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:17,282 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2\".\n",
      "180711-20:37:17,300 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Bilat.nii.gz --steplength=0.500\n",
      "180711-20:37:17,334 interface INFO:\n",
      "\t stderr 2018-07-11T20:37:17.334275:probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "180711-20:37:17,407 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2)\n",
      "180711-20:37:17,412 workflow ERROR:\n",
      "\t Node pbx2.aI.a0.b0 failed to run on host 145e230a3f42.\n",
      "180711-20:37:17,414 workflow ERROR:\n",
      "\t Saving crash info to /data/HCP_Data/Scripts/crash-20180711-203717-neuro-pbx2.aI.a0.b0-89741b2e-e0fe-4011-8d3b-bc8a9006892b.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 480, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 564, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/nodes.py\", line 644, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 521, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/fsl/dti.py\", line 780, in _run_interface\n",
      "    runtime = super(ProbTrackX, self)._run_interface(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 1034, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/nipype/interfaces/base/core.py\", line 971, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck -m /data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/nodif_brain_mask.nii.gz --nsamples=50 --nsteps=2000 --opd --dir=/data/HCP_Data/NipypeScratch/runpbx2/_subject_id_100206/_seed_..data..HCP_Data..EHECHT_ROIS..Human_BasalForebrain_Bilat.nii.gz/pbx2 --samples=/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/merged --seed=/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Bilat.nii.gz --steplength=0.500\n",
      "Standard output:\n",
      "\n",
      "Standard error:\n",
      "probtrackx2: error while loading shared libraries: libfslvtkio.so: cannot open shared object file: No such file or directory\n",
      "Return code: 127\n",
      "\n",
      "180711-20:37:17,419 workflow INFO:\n",
      "\t ***********************************\n",
      "180711-20:37:17,420 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a5.b1\n",
      "180711-20:37:17,421 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203715-neuro-pbx2.aI.a5.b1-a8c0a7c7-5907-4813-aa26-c4e6e37f9a57.pklz\n",
      "180711-20:37:17,422 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a4.b1\n",
      "180711-20:37:17,423 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203715-neuro-pbx2.aI.a4.b1-5e5c5b76-e3f9-4fca-a91f-ba3f7faa8df7.pklz\n",
      "180711-20:37:17,424 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a3.b1\n",
      "180711-20:37:17,425 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a3.b1-ef5cf9ce-351e-49d6-b151-8ac2bc90a438.pklz\n",
      "180711-20:37:17,426 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a2.b1\n",
      "180711-20:37:17,426 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a2.b1-308c9aa9-dca1-4ea4-a91a-18e364274250.pklz\n",
      "180711-20:37:17,427 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a1.b1\n",
      "180711-20:37:17,428 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a1.b1-b8af7f4e-416b-413a-8c45-3053094c9edb.pklz\n",
      "180711-20:37:17,429 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a0.b1\n",
      "180711-20:37:17,430 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a0.b1-2491c217-5a68-4bb4-a9c4-c27199c19ed5.pklz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180711-20:37:17,430 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a5.b0\n",
      "180711-20:37:17,431 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a5.b0-9a2ba8d9-2362-41f2-8ae8-bd2f74ce5255.pklz\n",
      "180711-20:37:17,432 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a4.b0\n",
      "180711-20:37:17,433 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a4.b0-33b5ab5d-9942-4975-9489-cedf79f16a63.pklz\n",
      "180711-20:37:17,434 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a3.b0\n",
      "180711-20:37:17,435 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203716-neuro-pbx2.aI.a3.b0-c734999e-4112-4ee0-ac8d-babe8965a44b.pklz\n",
      "180711-20:37:17,436 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a2.b0\n",
      "180711-20:37:17,436 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203717-neuro-pbx2.aI.a2.b0-613e098b-05b1-4f1d-bff1-bf6f9ffb1ce7.pklz\n",
      "180711-20:37:17,437 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a1.b0\n",
      "180711-20:37:17,438 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203717-neuro-pbx2.aI.a1.b0-623abcb1-fa0f-49c0-8e41-4d99d0b055ba.pklz\n",
      "180711-20:37:17,439 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.aI.a0.b0\n",
      "180711-20:37:17,440 workflow INFO:\n",
      "\t crashfile: /data/HCP_Data/Scripts/crash-20180711-203717-neuro-pbx2.aI.a0.b0-89741b2e-e0fe-4011-8d3b-bc8a9006892b.pklz\n",
      "180711-20:37:17,441 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-831586c7b3b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrunpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'thsamples'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_base_name_fxn\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'samples_base_name'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m###  NOTE THIS IS A WEIRD TUPLE IS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrunpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nipype/pipeline/engine/workflows.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/linear.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/nipype/pipeline/plugins/tools.py\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     82\u001b[0m                             'Check log for details'))\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "#runpbx.connect(subj_infosource,'subject_id',datasource,'subject_id')\n",
    "runpbx2  = pe.Workflow(name=\"runpbx2\")\n",
    "runpbx2.base_dir = \"/data/HCP_Data/NipypeScratch/\"\n",
    "\n",
    "samples_base_name_fxn = lambda x : x.replace('_th1samples.nii.gz','')\n",
    "\n",
    "\n",
    "runpbx2.connect(subj_infosource,'subject_id',datasource,'subject_id')\n",
    "# ### Connect the dti_datasource to the pbx2 command\n",
    "runpbx2.connect( datasource,'thsamples',pbx2,'thsamples')\n",
    "runpbx2.connect( datasource,'phsamples',pbx2,'phsamples')\n",
    "runpbx2.connect( datasource,'fsamples',pbx2,'fsamples')\n",
    "runpbx2.connect( datasource,'nodif_brain_mask',pbx2,'mask')\n",
    "runpbx2.connect( datasource, ('thsamples', samples_base_name_fxn ), pbx2,'samples_base_name') ###  NOTE THIS IS A WEIRD TUPLE IS\n",
    "\n",
    "runpbx2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Mandatory]\n",
    "fsamples: (a list of items which are an existing file name)\n",
    "mask: (an existing file name)\n",
    "        bet binary mask file in diffusion space\n",
    "        flag: -m %s\n",
    "phsamples: (a list of items which are an existing file name)\n",
    "seed: (an existing file name or a list of items which are an existing\n",
    "         file name or a list of items which are a list of from 3 to 3 items\n",
    "         which are an integer (int or long))\n",
    "        seed volume(s), or voxel(s)or freesurfer label file\n",
    "        flag: --seed=%s\n",
    "thsamples: (a list of items which are an existing file name)\n",
    "\n",
    "[Optional]\n",
    "args: (a string)\n",
    "        Additional parameters to the command\n",
    "        flag: %s\n",
    "avoid_mp: (an existing file name)\n",
    "        reject pathways passing through locations given by this mask\n",
    "        flag: --avoid=%s\n",
    "c_thresh: (a float)\n",
    "        curvature threshold - default=0.2\n",
    "        flag: --cthr=%.3f\n",
    "colmask4: (an existing file name)\n",
    "        Mask for columns of matrix4 (default=seed mask)\n",
    "        flag: --colmask4=%s\n",
    "correct_path_distribution: (a boolean)\n",
    "        correct path distribution for the length of the pathways\n",
    "        flag: --pd\n",
    "dist_thresh: (a float)\n",
    "        discards samples shorter than this threshold (in mm - default=0)\n",
    "        flag: --distthresh=%.3f\n",
    "distthresh1: (a float)\n",
    "        Discards samples (in matrix1) shorter than this threshold (in mm -\n",
    "        default=0)\n",
    "        flag: --distthresh1=%.3f\n",
    "distthresh3: (a float)\n",
    "        Discards samples (in matrix3) shorter than this threshold (in mm -\n",
    "        default=0)\n",
    "        flag: --distthresh3=%.3f\n",
    "environ: (a dictionary with keys which are a value of type 'str' and\n",
    "         with values which are a value of type 'str', nipype default value:\n",
    "         {})\n",
    "        Environment variables\n",
    "fibst: (an integer (int or long))\n",
    "        force a starting fibre for tracking - default=1, i.e. first fibre\n",
    "        orientation. Only works if randfib==0\n",
    "        flag: --fibst=%d\n",
    "fopd: (an existing file name)\n",
    "        Other mask for binning tract distribution\n",
    "        flag: --fopd=%s\n",
    "force_dir: (a boolean, nipype default value: True)\n",
    "        use the actual directory name given - i.e. do not add + to make a\n",
    "        new directory\n",
    "        flag: --forcedir\n",
    "ignore_exception: (a boolean, nipype default value: False)\n",
    "        Print an error message instead of throwing an exception in case the\n",
    "        interface fails to run\n",
    "inv_xfm: (a file name)\n",
    "        transformation matrix taking DTI space to seed space (compulsory\n",
    "        when using a warp_field for seeds_to_dti)\n",
    "        flag: --invxfm=%s\n",
    "loop_check: (a boolean)\n",
    "        perform loop_checks on paths - slower, but allows lower curvature\n",
    "        threshold\n",
    "        flag: --loopcheck\n",
    "lrtarget3: (an existing file name)\n",
    "        Column-space mask used for Nxn connectivity matrix\n",
    "        flag: --lrtarget3=%s\n",
    "meshspace: ('caret' or 'freesurfer' or 'first' or 'vox')\n",
    "        Mesh reference space - either \"caret\" (default) or \"freesurfer\" or\n",
    "        \"first\" or \"vox\"\n",
    "        flag: --meshspace=%s\n",
    "mod_euler: (a boolean)\n",
    "        use modified euler streamlining\n",
    "        flag: --modeuler\n",
    "n_samples: (an integer (int or long), nipype default value: 5000)\n",
    "        number of samples - default=5000\n",
    "        flag: --nsamples=%d\n",
    "n_steps: (an integer (int or long))\n",
    "        number of steps per sample - default=2000\n",
    "        flag: --nsteps=%d\n",
    "network: (a boolean)\n",
    "        activate network mode - only keep paths going through at least one\n",
    "        seed mask (required if multiple seed masks)\n",
    "        flag: --network\n",
    "omatrix1: (a boolean)\n",
    "        Output matrix1 - SeedToSeed Connectivity\n",
    "        flag: --omatrix1\n",
    "omatrix2: (a boolean)\n",
    "        Output matrix2 - SeedToLowResMask\n",
    "        flag: --omatrix2\n",
    "        requires: target2\n",
    "omatrix3: (a boolean)\n",
    "        Output matrix3 (NxN connectivity matrix)\n",
    "        flag: --omatrix3\n",
    "        requires: target3, lrtarget3\n",
    "omatrix4: (a boolean)\n",
    "        Output matrix4 - DtiMaskToSeed (special Oxford Sparse Format)\n",
    "        flag: --omatrix4\n",
    "onewaycondition: (a boolean)\n",
    "        Apply waypoint conditions to each half tract separately\n",
    "        flag: --onewaycondition\n",
    "opd: (a boolean, nipype default value: True)\n",
    "        outputs path distributions\n",
    "        flag: --opd\n",
    "os2t: (a boolean)\n",
    "        Outputs seeds to targets\n",
    "        flag: --os2t\n",
    "out_dir: (an existing directory name)\n",
    "        directory to put the final volumes in\n",
    "        flag: --dir=%s\n",
    "output_type: ('NIFTI_PAIR' or 'NIFTI_PAIR_GZ' or 'NIFTI_GZ' or\n",
    "         'NIFTI')\n",
    "        FSL output type\n",
    "rand_fib: (0 or 1 or 2 or 3)\n",
    "        options: 0 - default, 1 - to randomly sample initial fibres (with f\n",
    "        > fibthresh), 2 - to sample in proportion fibres (with f>fibthresh)\n",
    "        to f, 3 - to sample ALL populations at random (even if f<fibthresh)\n",
    "        flag: --randfib=%d\n",
    "random_seed: (a boolean)\n",
    "        random seed\n",
    "        flag: --rseed\n",
    "s2tastext: (a boolean)\n",
    "        output seed-to-target counts as a text file (useful when seeding\n",
    "        from a mesh)\n",
    "        flag: --s2tastext\n",
    "sample_random_points: (a boolean)\n",
    "        sample random points within seed voxels\n",
    "        flag: --sampvox\n",
    "samples_base_name: (a string, nipype default value: merged)\n",
    "        the rootname/base_name for samples files\n",
    "        flag: --samples=%s\n",
    "seed_ref: (an existing file name)\n",
    "        reference vol to define seed space in simple mode - diffusion space\n",
    "        assumed if absent\n",
    "        flag: --seedref=%s\n",
    "simple: (a boolean)\n",
    "        rack from a list of voxels (seed must be a ASCII list of\n",
    "        coordinates)\n",
    "        flag: --simple\n",
    "step_length: (a float)\n",
    "        step_length in mm - default=0.5\n",
    "        flag: --steplength=%.3f\n",
    "stop_mask: (an existing file name)\n",
    "        stop tracking at locations given by this mask file\n",
    "        flag: --stop=%s\n",
    "target2: (an existing file name)\n",
    "        Low resolution binary brain mask for storing connectivity\n",
    "        distribution in matrix2 mode\n",
    "        flag: --target2=%s\n",
    "target3: (an existing file name)\n",
    "        Mask used for NxN connectivity matrix (or Nxn if lrtarget3 is set)\n",
    "        flag: --target3=%s\n",
    "target4: (an existing file name)\n",
    "        Brain mask in DTI space\n",
    "        flag: --target4=%s\n",
    "target_masks: (a list of items which are a file name)\n",
    "        list of target masks - required for seeds_to_targets classification\n",
    "        flag: --targetmasks=%s\n",
    "terminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
    "        Control terminal output: `stream` - displays to terminal immediately\n",
    "        (default), `allatonce` - waits till command is finished to display\n",
    "        output, `file` - writes output to file, `none` - output is ignored\n",
    "use_anisotropy: (a boolean)\n",
    "        use anisotropy to constrain tracking\n",
    "        flag: --usef\n",
    "verbose: (0 or 1 or 2)\n",
    "        Verbose level, [0-2].Level 2 is required to output particle files.\n",
    "        flag: --verbose=%d\n",
    "waycond: ('OR' or 'AND')\n",
    "        Waypoint condition. Either \"AND\" (default) or \"OR\"\n",
    "        flag: --waycond=%s\n",
    "wayorder: (a boolean)\n",
    "        Reject streamlines that do not hit waypoints in given order. Only\n",
    "        valid if waycond=AND\n",
    "        flag: --wayorder\n",
    "waypoints: (an existing file name)\n",
    "        waypoint mask or ascii list of waypoint masks - only keep paths\n",
    "        going through ALL the masks\n",
    "        flag: --waypoints=%s\n",
    "xfm: (an existing file name)\n",
    "        transformation matrix taking seed space to DTI space (either FLIRT\n",
    "        matrix or FNIRT warp_field) - default is identity\n",
    "        flag: --xfm=%s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runpbx2.connect( dti_datasource, ('thsamples',samples_base_name_fxn) ,pbx2,'samples_base_name')\n",
    "# # Run tractography with warp to/from template space\n",
    "# $statement .= \" -s $WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/merged \"; \n",
    "# $statement .= \" -x $WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_WM.nii.gz \";  ## check downsample\n",
    "# $statement .= \" -l   --fibthresh=0.1 --randfib=0 \";  ## check # of samples\n",
    "# $statement .= \" --forcedir --opd \";\n",
    "# $statement .= \" --dir=$WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/WholeBrainMatrixConnectivity_TemplateSpace_fullres/ \";\n",
    "# print \"$statement \\n\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = dict(\n",
    "            thsamples = [['subject_id','th1samples']],\n",
    "            phsamples =  [['subject_id','ph1samples']],\n",
    "            fsamples =  [['subject_id','f1samples']],\n",
    "            nodif_brain_mask = [['subject_id','nodif_brain_mask']],\n",
    "            xfm = [['subject_id','acpc_dc2standard.nii.gz']],\n",
    "            invxfm = [['subject_id', 'standard2acpc_dc.nii.gz' ]] \n",
    "            )\n",
    "\n",
    "info_template  = {'nodif_brain_mask': '%s/data.bedpostX/%s.nii.gz',    \n",
    "    'thsamples' : '%s/data.bedpostX/merged_%s.nii.gz',\n",
    "    'phsamples' : '%s/data.bedpostX/merged_%s.nii.gz',\n",
    "    'fsamples' : '%s/data.bedpostX/merged_%s.nii.gz',\n",
    "    'xfm': \"%s/xfms/%s\",\n",
    "    'invxfm' :\"%s/xfms/%s\"\n",
    "}\n",
    "\n",
    "\n",
    "dti_datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "                                               outfields=info.keys()),\n",
    "                                                 name='dti_datasource')\n",
    "dti_datasource.inputs.base_directory = subjRootDir \n",
    "dti_datasource.inputs.sort_filelist = True\n",
    "#dti_datasource.inputs.template = '*'\n",
    "dti_datasource.inputs.field_template = info_template\n",
    "\n",
    "dti_datasource.inputs.template_args = info\n",
    "## Just mapped each subject to the corresponding bvec,bvals, brain mask and preprocessed DWI data\n",
    "### Create the Node for DTIFIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>> dg = DataGrabber(infields=['sid'], outfields=['func','struct','ref'])\n",
    "# >>> dg.inputs.base_directory = '.'\n",
    "# >>> dg.inputs.template = '%s/%s.nii'\n",
    "# >>> dg.inputs.template_args['func'] = [['sid',['f3','f5']]]\n",
    "# >>> dg.inputs.template_args['struct'] = [['sid',['struct']]]\n",
    "# >>> dg.inputs.template_args['ref'] = [['sid','ref']]\n",
    "# >>> dg.inputs.sid = 's1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample Subject = /HCP_Data/HCP_BedpostData/106016/T1w/Diffusion.bedpostX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT_LIST = ['106016']\n",
    "\n",
    "subject_id_infosource = pe.Node(util.IdentityInterface(fields=['subject_id']),\n",
    "                                name='subject_id_infosource')\n",
    "subject_id_infosource.iterables = ('subject_id', FULL_SUBJECT_LIST[0:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "                                               outfields=['dwi', 'bvec', 'bval']),\n",
    "                                                 name='datasource')\n",
    "datasource.inputs.base_directory = subjRootDir \n",
    "datasource.inputs.sort_filelist = True\n",
    "\n",
    "pbx2 = pe.Node(interface=fsl.ProbTrackX2(), name='pbx2')\n",
    "pbx2.inputs.c_thresh = 0.2\n",
    "pbx2.inputs.correct_path_distribution = True\n",
    "pbx2.inputs.n_samples  = 5000\n",
    "pbx2.inputs.loop_check = True\n",
    "pbx2.inputs.step_length = 0.5\n",
    "pbx2.inputs.rand_fib = 0\n",
    "\n",
    "#probtrackx2 --omatrix2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --pd   correct_path_distribution \n",
    "#-l\n",
    "#-c 0.2    --->> c_thresh\n",
    "#-S 2000   \n",
    "#--steplength=0.5\n",
    "#-P 5000    n_samples\n",
    "#--fibthresh=0.1   \n",
    "#--randfib=0  rand_fib\n",
    "#-s /home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/Subj_026/data.bedpostX/merged \n",
    "#-m /home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/Subj_026/data/nodif_brain_mask.nii.gz\n",
    "#-x /home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/ROIs/Human_BasalForebrain_Left.nii.gz \n",
    "#--target2=/home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/ROIs/MNI152_T1_1mm_brain_mask.nii.gz \n",
    "#--xfm=/home/ehecht/TEMPLETON/Templeton_Registration/xfms/Subj_026_Scan2_MNI_fnirt_struct_6dof-flirt_nodif.nii.gz\n",
    "#--invxfm=/home/ehecht/TEMPLETON/Templeton_Registration/xfms/Subj_026_Scan2_nodif_6dof-flirt_struct_fnirt_MNI.nii.gz \n",
    "#--forcedir \n",
    "#--opd\n",
    "#--dir=/home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/Subj_026/BasalForebrain_Left_TemplateSpace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pbx2.inputs.seed = 'seed_source.nii.gz'\n",
    "# >>> pbx2.inputs.thsamples = 'merged_th1samples.nii.gz'\n",
    "# >>> pbx2.inputs.fsamples = 'merged_f1samples.nii.gz'\n",
    "# >>> pbx2.inputs.phsamples = 'merged_ph1samples.nii.gz'\n",
    "# >>> pbx2.inputs.mask = 'nodif_brain_mask.nii.gz'\n",
    "# >>> pbx2.inputs.out_dir = '.'\n",
    "# >>> pbx2.inputs.n_samples = 3\n",
    "# >>> pbx2.inputs.n_steps = 10\n",
    "# >>> pbx2.cmdline\n",
    "\n",
    "# datasource.inputs.template = '%s/T1w/Diffusion/%s'\n",
    "# datasource.inputs.template_args = dict(dwi=[['subject_id', 'data.nii.gz']],\n",
    "#                                        bvecs=[['subject_id', 'bvecs']],\n",
    "#                                        bvals=[['subject_id', 'bvals']],\n",
    "#                                        nodif_brain_mask=[['subject_id','nodif_brain_mask.nii.gz']])\n",
    "## Just mapped each subject to the corresponding bvec,bvals, brain mask and preprocessed DWI data\n",
    "### Create the Node for DTIFIT\n",
    "# dtifit = pe.Node(interface=fsl.DTIFit(), name='dtifit')\n",
    "\n",
    "\n",
    "# gen_fa = pe.Workflow(name=\"gen_fa\")\n",
    "# gen_fa.base_dir = '/data/HCP_Data/NipypeScratch/'\n",
    "# gen_fa.connect(subject_id_infosource, 'subject_id', datasource, 'subject_id')\n",
    "\n",
    "# gen_fa.connect(subject_id_infosource, 'subject_id', dtifit, 'base_name')\n",
    "# gen_fa.connect(datasource, 'bvecs', dtifit, 'bvecs')\n",
    "# gen_fa.connect(datasource, 'bvals', dtifit, 'bvals')\n",
    "# gen_fa.connect(datasource, 'nodif_brain_mask', dtifit, 'mask')\n",
    "# gen_fa.connect(datasource, 'dwi', dtifit, 'dwi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_fa.write_graph(graph2use='colored',simple_form=False))\n",
    "Image('/data/HCP_Data/NipypeScratch/gen_fa/graph.png')\n",
    "#Image('/data/HCP_Data/NipypeScratch/gen_fa/graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fa.run(plugin='MultiProc', plugin_args={'n_procs' : 20})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /data/HCP_Data/HCP_BedpostData/106016/T1w/Diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasink = pe.Node(interface=nio.DataSink(), name=\"datasink\")\n",
    "datasink.inputs.base_directory = os.path.join(os.path.abspath(working_data_dir),\n",
    "                                              'sri_results')\n",
    "datasink.inputs.parameterization = False\n",
    "gen_fa.connect(dtifit, 'FA', datasink, 'FA')\n",
    "gen_fa.connect(dtifit, 'MD', datasink, 'MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traits.api import HasTraits, Directory, Bool\n",
    "import traits.api as traits\n",
    "from ....base import MetaWorkflow, load_config, register_workflow\n",
    "from wip_diffusion import config as pconfig\n",
    "from bips.workflows.base import BaseWorkflowConfig\n",
    "\n",
    "\"\"\"\n",
    "Part 1: MetaWorkflow\n",
    "\"\"\"\n",
    "mwf = MetaWorkflow()\n",
    "mwf.help = \"\"\"\n",
    "Diffusion tracking workflow\n",
    "===========================\n",
    "\"\"\"\n",
    "mwf.uuid = 'fda82554a43511e1b507001e4fb1404c'\n",
    "mwf.tags = ['diffusion','dti','tracking']\n",
    "mwf.script_dir = 'fmri'\n",
    "\n",
    "\"\"\"\n",
    "Part 2: Config\n",
    "\"\"\"\n",
    "\n",
    "class config(BaseWorkflowConfig):\n",
    "    uuid = traits.Str(desc=\"UUID\")\n",
    "    desc = traits.Str(desc='Workflow description')\n",
    "    # Directories\n",
    "    sink_dir = Directory(mandatory=True, desc=\"Location where the BIP will store the results\")\n",
    "    \n",
    "    # Subjects\n",
    "\n",
    "    subjects= traits.List(traits.Str, mandatory=True, usedefault=True,\n",
    "        desc=\"Subject id's. Note: These MUST match the subject id's in the \\\n",
    "                                Freesurfer directory. For simplicity, the subject id's should \\\n",
    "                                also match with the location of individual functional files.\")\n",
    "    # Preprocessing info\n",
    "    preproc_config = traits.File(desc=\"preproc json file\")\n",
    "\n",
    "    #Advanced\n",
    "    use_advanced_options = traits.Bool()\n",
    "    advanced_script = traits.Code()\n",
    "    save_script_only = traits.Bool(False)\n",
    "\n",
    "def create_config():\n",
    "    c = config()\n",
    "    c.uuid = mwf.uuid\n",
    "    c.desc = mwf.help\n",
    "    return c\n",
    "\n",
    "mwf.config_ui = create_config\n",
    "\n",
    "\"\"\"\n",
    "Part 3: View\n",
    "\"\"\"\n",
    "\n",
    "def create_view():\n",
    "    from traitsui.api import View, Item, Group, CSVListEditor\n",
    "    from traitsui.menu import OKButton, CancelButton\n",
    "    view = View(Group(Item(name='uuid', style='readonly'),\n",
    "        Item(name='desc', style='readonly'),\n",
    "        label='Description', show_border=True),\n",
    "        Group(Item(name='working_dir'),\n",
    "            Item(name='sink_dir'),\n",
    "            Item(name='crash_dir'),\n",
    "            label='Directories', show_border=True),\n",
    "        Group(Item(name='run_using_plugin'),\n",
    "            Item(name='plugin', enabled_when=\"run_using_plugin\"),\n",
    "            Item(name='plugin_args', enabled_when=\"run_using_plugin\"),\n",
    "            Item(name='test_mode'),\n",
    "            label='Execution Options', show_border=True),\n",
    "        Group(Item(name='subjects', editor=CSVListEditor()),\n",
    "            label='Subjects', show_border=True),\n",
    "        Group(Item(name='preproc_config'),\n",
    "            label='Track', show_border=True),\n",
    "        Group(Item(\"use_advanced_options\"),\n",
    "            Item(\"advanced_script\"),\n",
    "            label=\"Advanced\",show_border=True),\n",
    "        buttons = [OKButton, CancelButton],\n",
    "        resizable=True,\n",
    "        width=1050)\n",
    "    return view\n",
    "\n",
    "mwf.config_view = create_view\n",
    "\n",
    "\"\"\"\n",
    "Part 4: Construct Workflow\n",
    "\"\"\"\n",
    "\n",
    "from ..scripts.diffusion_base import create_workflow\n",
    "\n",
    "def get_dataflow(c):\n",
    "    import nipype.pipeline.engine as pe\n",
    "    import nipype.interfaces.io as nio\n",
    "    datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "        outfields=['dwi','mask','bvecs','bvals',\"reg\",\"mean\"]),\n",
    "        name='datasource')\n",
    "    # create a node to obtain the functional images\n",
    "    datasource.inputs.base_directory = c.sink_dir\n",
    "    datasource.inputs.template ='*'\n",
    "    datasource.inputs.field_template = dict(dwi='%s/preproc/outputs/dwi/*',\n",
    "        mask='%s/preproc/outputs/mask/*', bvecs='%s/preproc/outputs/bvecs/*',\n",
    "        bvals='%s/preproc/outputs/bvals/*',reg='%s/preproc/outputs/bbreg/*.dat',\n",
    "        mean='%s/preproc/outputs/mean/*.nii*')\n",
    "    datasource.inputs.template_args = dict(dwi=[['subject_id']],\n",
    "        mask=[['subject_id']],\n",
    "        bvecs=[['subject_id']],\n",
    "        bvals=[['subject_id']],\n",
    "        mean=[[\"subject_id\"]],\n",
    "        reg=[[\"subject_id\"]])\n",
    "    return datasource\n",
    "\n",
    "foo = pconfig()\n",
    "\n",
    "def get_wf(c, prep_c=foo):\n",
    "    import nipype.pipeline.engine as pe\n",
    "    import nipype.interfaces.io as nio\n",
    "    import nipype.interfaces.utility as niu\n",
    "    workflow = create_workflow()\n",
    "    datagrabber = get_dataflow(prep_c)\n",
    "    inputspec = workflow.get_node('inputspec')\n",
    "    workflow.connect(datagrabber,'mask',inputspec,'mask')\n",
    "    workflow.connect(datagrabber,'dwi',inputspec,'dwi')\n",
    "    workflow.connect(datagrabber,'bvecs',inputspec,'bvecs')\n",
    "    workflow.connect(datagrabber,'bvals',inputspec,'bvals')\n",
    "    workflow.connect(datagrabber,'reg',inputspec,'reg')\n",
    "    workflow.connect(datagrabber,'mean',inputspec,'mean')\n",
    "    workflow.inputs.inputspec.surf_dir=prep_c.surf_dir\n",
    "    infosource = pe.Node(niu.IdentityInterface(fields=[\"subject_id\"]),name='subject_names')\n",
    "    workflow.connect(infosource,\"subject_id\",datagrabber, 'subject_id')\n",
    "    workflow.connect(infosource,\"subject_id\",inputspec, 'subject_id')\n",
    "    sinker = pe.Node(nio.DataSink(),name='sinker')\n",
    "    outputspec=workflow.get_node('outputspec')\n",
    "    workflow.connect(outputspec,'fdt_paths',sinker,'track.fdt_paths')\n",
    "    workflow.connect(outputspec,'log',sinker,'track.log')\n",
    "    workflow.connect(outputspec,'particle_files',sinker,'track.particle_files')\n",
    "    workflow.connect(outputspec,'targets',sinker,'track.targets')\n",
    "    workflow.connect(outputspec,'way_total',sinker,'track.way_total')\n",
    "    sinker.inputs.base_directory=c.sink_dir\n",
    "    workflow.connect(infosource,\"subject_id\",sinker,\"container\")\n",
    "\n",
    "    if c.test_mode:\n",
    "        infosource.iterables=(\"subject_id\", [c.subjects[0]])\n",
    "    else:\n",
    "        infosource.iterables=(\"subject_id\", c.subjects)\n",
    "    workflow.base_dir = c.working_dir\n",
    "    return workflow\n",
    "\n",
    "mwf.workflow_function = get_wf\n",
    "\n",
    "\"\"\"\n",
    "Part 5: Main\n",
    "\"\"\"\n",
    "\n",
    "def main(config_file):\n",
    "    c = load_config(config_file,config)\n",
    "\n",
    "    prep_c = load_config(c.preproc_config, pconfig)\n",
    "\n",
    "    workflow = get_wf(c,prep_c)\n",
    "\n",
    "    if c.use_advanced_options:\n",
    "        exec c.advanced_script\n",
    "\n",
    "    if c.test_mode:\n",
    "        workflow.write_graph()\n",
    "\n",
    "    if c.run_using_plugin:\n",
    "        workflow.run(plugin=c.plugin, plugin_args=c.plugin_args)\n",
    "    else:\n",
    "        workflow.run()\n",
    "\n",
    "    return 1\n",
    "\n",
    "mwf.workflow_main_function = main\n",
    "\n",
    "\"\"\"\n",
    "Part 6: Main\n",
    "\"\"\"\n",
    "\n",
    "register_workflow(mwf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "\n",
    "subjDir = \"/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/\"\n",
    "\n",
    "pbx2 = fsl.ProbTrackX2()\n",
    "pbx2.inputs.seed = '/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Left.nii.gz'\n",
    "pbx2.inputs.thsamples = subjDir + 'merged_th1samples.nii.gz'\n",
    "pbx2.inputs.fsamples =  subjDir + 'merged_f1samples.nii.gz'\n",
    "pbx2.inputs.phsamples =  subjDir + 'merged_ph1samples.nii.gz'\n",
    "pbx2.inputs.mask =  subjDir + 'nodif_brain_mask.nii.gz'\n",
    "pbx2.inputs.out_dir = '.'\n",
    "pbx2.inputs.n_samples = 3\n",
    "pbx2.inputs.n_steps = 10\n",
    "pbx2.cmdline\n",
    "pbx2.run()\n",
    "#'probtrackx2 --forcedir -m nodif_brain_mask.nii.gz --nsamples=3 --nstep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Nipype Workflow for ProbTrackX2 fdt_path waypath thresholding and normalization\n",
    "## DG Version 1: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import config\n",
    "import os,glob,sys,shutil\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.interfaces.io as nio\n",
    "from nipype.interfaces.fsl import Info\n",
    "from nipype.interfaces.ants import WarpImageMultiTransform\n",
    "\n",
    "MNI_template = Info.standard_image('MNI152_T1_1mm_brain.nii.gz')\n",
    "\n",
    "\n",
    "cfg = dict(execution={'remove_unnecessary_outputs': False,\n",
    "                      'keep_inputs': True},\n",
    "           monitoring={'enabled': True,\n",
    "                       'sample_frequency': 5}\n",
    "          )\n",
    "config.update_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for DataGrabber inputs needed for thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "        outfields=['nodif_brain','affDTItoStruct','affStructToMNI','warpStructToMNI',\n",
    "                   'invWarpStructToMNI','lHypo']),\n",
    "        name='datasource')\n",
    "# create a node to obtain the functional images\n",
    "datasource.inputs.base_directory = \"/data/HCP_Data/HCP_BedpostData/\"\n",
    "datasource.inputs.template ='*'\n",
    "datasource.inputs.sort_filelist = True\n",
    "\n",
    "datasource.inputs.field_template = dict(\n",
    "    nodif_brain='%s/T1w/Diffusion/nodif_brain.nii.gz', \n",
    "    affDTItoStruct='addlInfo/subject/%s/dtiToStruct0GenericAffine.mat',\n",
    "    affStructToMNI='addlInfo/subject/%s/structToMNI0GenericAffine.mat',\n",
    "    warpStructToMNI='addlInfo/subject/%s/structToMNI1Warp.nii.gz',\n",
    "    invWarpStructToMNI='addlInfo/subject/%s/structToMNI1InverseWarp.nii.gz',\n",
    "    lHypo='addlInfo/subject/%s/pbxResults/DTI/Human_BasalForebrain_Left_fdt_paths.nii.gz'\n",
    "    )\n",
    "\n",
    "datasource.inputs.template_args = dict(\n",
    "    nodif_brain=[['subject_id']], \n",
    "    affDTItoStruct=[['subject_id']],\n",
    "    affStructToMNI=[['subject_id']],\n",
    "    warpStructToMNI=[['subject_id']],\n",
    "    invWarpStructToMNI=[['subject_id']],\n",
    "    lHypo=[['subject_id']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjRootDir = \"/data/HCP_Data/HCP_BedpostData/\"\n",
    "FULL_SUBJECT_LIST = [x for x in os.listdir(subjRootDir) if os.path.isdir( subjRootDir+'/addlInfo/subject/'+x+'/pbxResults/DTI')]\n",
    "print(len(FULL_SUBJECT_LIST),\"Subjects are potentially available to be processed!\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Setup for Normalized pbx2 results Computational Pipeline\n",
    "\"\"\"\n",
    "subj_infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),  name=\"subj_infosource\")\n",
    "#infosource.iterables = ('subject_id', SampleSubjList)\n",
    "subj_infosource.iterables = ('subject_id', FULL_SUBJECT_LIST[:10])\n",
    "### Above just converts the list of subjects into an iterable list I can connect to the next part of the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold and then Normalize images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node: Function: Thresholds using FSL Maths\n",
    "# ifiles: original input file\n",
    "Threshold = pe.Node(fsl.Threshold(),\n",
    "                 name = 'Threshold')\n",
    "\n",
    "# Node: Function: Normalizes using FSL Maths -div\n",
    "Normalize = pe.Node(fsl.BinaryMaths(operation='div'),\n",
    "                 name = 'Normalize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Had a default but we deleted it for now\n",
    "### TScaling was = 100000\n",
    "def getWaytotal(in_file, Tscaling): \n",
    "    import subprocess\n",
    "    import re\n",
    "    \n",
    "    in_file= re.sub('fdt_paths.nii.gz', 'waytotal', in_file)\n",
    "    mycommand= \"cat \"+str(in_file)\n",
    "    mycommand= mycommand.split(sep=' ')\n",
    "    result= subprocess.run(mycommand, stdout=subprocess.PIPE)\n",
    "    tmpwaytotal= result.stdout.decode(\"utf-8\").split(' ')[0]\n",
    "    print('waytotal: %s' % tmpwaytotal)\n",
    "    \n",
    "    if(not tmpwaytotal): \n",
    "        print('Waytotal Empty for: %s' % pathwaytotal)\n",
    "    else:\n",
    "        waytotals= float(tmpwaytotal) / Tscaling                \n",
    "        return( waytotals )\n",
    "    \n",
    "    \n",
    "from nipype.interfaces.utility import Function\n",
    "getWaytotal_node = pe.Node( name=\"getWaytotal_node\",iterfield=[\"Tscaling\"],\n",
    "                           interface=Function(input_names=[\"in_file\",\"Tscaling\"],\n",
    "                            output_names=[\"waytotal\"],\n",
    "                             function=getWaytotal)\n",
    "                          )\n",
    "\n",
    "getWaytotal_node.iterables = (\"Tscaling\",  [5000,1000,100,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Register thresholded results to the MNI Space for further analysis\n",
    "###WARPING PBX RESULTS TO MNI SPACE--- THIS IS THE SAME WAY WE COMPUTED THE ACTUAL TRANSFORMS\n",
    "#an@frink:/HCP_Data/Scripts/GutmanLabNipypeWorkflows/HCP_Pipelines/testThreshold$ WarpImageMultiTransform 3 nodif_brain.nii.gz nodif_to_mni_debug_warp_strucToMNI_dtiToStruct.nii.gz  -R /usr/share/fsl/5.0/data/standard/MNI152_T1_1mm.nii.gz --use-NN ./structToMNI1Warp.nii.gz ./structToMNI0GenericAffine.mat ./dtiToStruct0GenericAffine.mat \n",
    "\n",
    "warp_pbxDTI_to_MNI = pe.Node( WarpImageMultiTransform(use_nearest=True,reference_image=MNI_template), \n",
    "                             name=\"warp_pbxDTI_to_MNI\")\n",
    "\n",
    "## Create a merge node to store the XFMS\n",
    "merge_xfms = pe.Node(util.Merge(3), name='merge_xfms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  I NEED THE WAYTOTAL AND THE SCALED WAYTOTAL.... OOPS!!!\n",
    "\n",
    "\n",
    "# Workflow: Initialize\n",
    "wf = pe.Workflow(name=\"threshAndWarpPBX\")\n",
    "wf.base_dir = '/data/HCP_Data/NipypeScratch/'\n",
    "wf.connect(subj_infosource,'subject_id',datasource,'subject_id')\n",
    "\n",
    "# ### Connect the dti_datasource to the pbx2 command\n",
    "wf.connect( datasource,'lHypo',Threshold,'in_file')\n",
    "wf.connect( datasource,'lHypo',getWaytotal_node,'in_file')\n",
    "\n",
    "wf.connect(getWaytotal_node,'waytotal',Threshold,'thresh')\n",
    "wf.connect( Threshold,'out_file',Normalize,'in_file')\n",
    "wf.connect(getWaytotal_node,'waytotal',Normalize,'operand_value')\n",
    "\n",
    "\n",
    "wf.connect(datasource,'warpStructToMNI',merge_xfms,\"in1\")\n",
    "wf.connect(datasource,'affStructToMNI',merge_xfms,\"in2\")\n",
    "wf.connect(datasource,'affDTItoStruct',merge_xfms,\"in3\")\n",
    "\n",
    "## Connect the pbx2 results I want to warp\n",
    "#wf.connect(datasource,\"lHypo\",warp_pbxDTI_to_MNI,\"input_image\")\n",
    "wf.connect(Normalize,\"out_file\",warp_pbxDTI_to_MNI,\"input_image\")\n",
    "wf.connect( merge_xfms,  'out', warp_pbxDTI_to_MNI, 'transformation_series')\n",
    "\n",
    "### need to make sure I feed the same modified waytotal to both functions\n",
    "wf.run()\n",
    "# Run Workflow\n",
    "#wf.run()\n",
    "# wf.run(plugin='MultiProc', plugin_args={'n_procs': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WarpImageMultiTransform 3 /usr/share/fsl/5.0/data/standard/MNI152_T1_1mm.nii.gz mni_to_dti.nii.gz -R /HCP_Data/HCP_BedpostData/162228/T1w/Diffusion/nodif_brain.nii.gz --use-NN\n",
    "#./structToMNI1InverseWarp.nii.gz -i \n",
    "#./structToMNI0GenericAffine.mat -i ./dtiToStruct0GenericAffine.mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workflows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect Nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOutput(x):\n",
    "    import re\n",
    "    \n",
    "    x= re.search('_id_(.*?).._seed_..data.*EHECHT_ROIS..(.*?)_(.*?)_(.*?).nii.gz', x)\n",
    "    x= '%s_%s_%s_%s' % (x.group(1), x.group(2), x.group(3), x.group(4))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect Nodes\n",
    "wf.connect(infosource, \"fdt_paths\", Normalize, \"in_file\")\n",
    "wf.connect(infosource, (\"fdt_paths\", getWaytotal), Normalize, \"operand_value\")\n",
    "wf.connect(Normalize, \"out_file\", Threshold, \"in_file\")\n",
    "\n",
    "#wf.connect(Threshold, (\"out_file\", cleanOutput), Sink, \"container\")\n",
    "#wf.connect(Threshold, \"out_file\", Sink, \"container.results\")\n",
    "\n",
    "wf.connect(Threshold, (\"out_file\", cleanOutput), Sink, \"base_directory\")\n",
    "wf.connect(Threshold, \"out_file\", Sink, \"container\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow: Graph: Exec\n",
    "wf.write_graph(graph2use='exec', dotfilename='/output/graph_exec.dot')\n",
    "#wf.write_graph(graph2use='hierarchical', dotfilename='/output/graph_exec.dot')\n",
    "\n",
    "# Visualize graph\n",
    "Image(filename=\"/output/graph_exec.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print final directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# Print directory structure\n",
    "tree -C -I \"*.nii.gz\" /data/SASRAID/ThreshNipype/output | grep -v -e \".*report\" -e \".*pklz\" -e \".*json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate subject file lists for each feature in group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaloc= '/code/notebooks/postPBX/unrestricted_dagutman_7_12_2018_15_39_53.csv'\n",
    "group='Gender'\n",
    "feature='M'\n",
    "bedpostx_dir= '/data/NipypeScratch/runpbx2/*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bedpostx_results= [subject_directories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedpostx_results= [ fn for fn in glob.glob(bedpostx_dir) if re.search( '[0-9][0-9]$', fn)  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### subjectinfo= {subject_id: {'waytotals': [paths], 'fdt_paths': [paths]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectinfo= {}\n",
    "for i in bedpostx_results:\n",
    "    output_sid= re.search('_id_(.*)', i).group(1)\n",
    "    waytotals= glob.glob( i+'/_seed*/pbx2/waytotal' )\n",
    "    fdt_paths= glob.glob( i+'/_seed*/pbx2/fdt_paths.nii.gz' )\n",
    "    subjectinfo[output_sid]={}\n",
    "    subjectinfo[output_sid]['waytotals']= waytotals\n",
    "    subjectinfo[output_sid]['fdt_paths']= fdt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata= pd.read_csv(metaloc,header=0)\n",
    "metadata_group= finalmetadata.groupby(by=group)\n",
    "metadata_feature= list( metadata_group.get_group(feature)['FDT_Paths'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Males\n",
    "### Merge Females"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls /data/NipypeScratch/runpbx2/_subject_id_880157/_seed*/pbx2/waytotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= '/data/NipypeScratch/runpbx2/_subject_id_880157/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2/waytotal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycommand= \"cat \"+A\n",
    "mycommand= mycommand.split(sep=' ')\n",
    "result= subprocess.run(mycommand, stdout=subprocess.PIPE)\n",
    "int( result.stdout )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat '/data/NipypeScratch/runpbx2/_subject_id_880157/_seed_..data..HCP_Data..EHECHT_ROIS..Human_Hypothalamus_Right.nii.gz/pbx2/waytotal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /NipypeScratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infosource = Node(IdentityInterface(fields=['fdt_path']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('fdt_path', fdt_paths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## STEPS \n",
    "\n",
    "\n",
    "\n",
    "### GET WAYTOTAL FOR the TRACTOGRAPHY RUN\n",
    "## calculate the threshold which is   0.1% or 0.01%  i.e. 0.001 and 0.0001 * waytotal\n",
    "### fslmaths fdt_paths.nii.gz -thr <somenumber> -div waytotal (or waytotal/1000 so numbers are not 00000000)\n",
    "\n",
    "\n",
    "## THEN CONVERT RESULTS TO MNI SPACE---   AAH CHA!! OK\n",
    "\n",
    "\n",
    "## THEN ADD EM UP AND MAKE A MAP...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "from IPython.display import Image\n",
    "\n",
    "from nipype import SelectFiles, Node, MapNode, Workflow, Function\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.fsl import ExtractROI\n",
    "from nipype.interfaces.fsl import ImageStats\n",
    "from nipype.interfaces.io import DataSink\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "\n",
    "import networkx\n",
    "import graphviz as gv\n",
    "import os\n",
    "import base64\n",
    "import re\n",
    "import glob\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input,Output\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "init_notebook_mode(connected=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

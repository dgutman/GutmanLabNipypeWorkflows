{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype\n",
    "import os,glob,sys,shutil\n",
    "sys.path.append(\"/usr/lib/ants/\")\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.interfaces.ants.legacy as antsL\n",
    "import nipype.interfaces.ants as ants\n",
    "from nipype.interfaces.ants import Registration\n",
    "from nipype.interfaces.ants import RegistrationSynQuick\n",
    "from IPython.display import Image\n",
    "from nipype.caching import Memory\n",
    "\n",
    "\n",
    "mem = Memory(base_dir='/data/HCP_Data/NipypeScratch/')\n",
    "regScratchDir = \"/data/HCP_Data/NipypeScratch/run_hcp_reg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Setup for DataGrabber inputs needed for the registration pipeline; This is using the freesurfer nodif and t1 masks\n",
    "# \"\"\"\n",
    "ds = nio.DataGrabber(infields=['subject_id'],\n",
    "    outfields=['nodif_brain','nodif_brain_mask','struct','struct_mask','struct_brain'])\n",
    "\n",
    "datasource = pe.Node(interface=ds,name=\"datasource\")\n",
    "# create a node to obtain the functional images\n",
    "datasource.inputs.base_directory = \"/data/HCP_Data/HCP_BedpostData/\"\n",
    "datasource.inputs.template ='*'\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.field_template = dict(\n",
    "    nodif_brain='%s/T1w/Diffusion/nodif_brain.nii*',\n",
    "    nodif_brain_mask='%s/T1w/Diffusion/nodif_brain_mask.nii*',\n",
    "    struct='%s/T1w/T1w_acpc_dc.nii*',\n",
    "    struct_mask='%s/T1w/brainmask_fs.nii*', \n",
    "    struct_brain='%s/T1w/T1w_acpc_dc_masked.nii*'\n",
    ")\n",
    "\n",
    "datasource.base_dir=\"/data/HCP_Data/NipypeScratch/datasource_cache_1\"\n",
    "datasource.inputs.template_args = dict(\n",
    "             nodif_brain = [['subject_id']],\n",
    "             nodif_brain_mask =  [['subject_id']],\n",
    "             struct =  [['subject_id']],\n",
    "             struct_mask = [['subject_id']],\n",
    "             struct_brain = [['subject_id']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjRootDir = \"/data/HCP_Data/HCP_BedpostData/\"\n",
    "FULL_SUBJECT_LIST = [x for x in os.listdir(subjRootDir) if os.path.isdir( subjRootDir+x+'/T1w/Diffusion.bedpostX')]\n",
    "print(len(FULL_SUBJECT_LIST),\"Subjects are potentially available to be processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource.inputs.raise_on_empty = False\n",
    "completeSubjs = []\n",
    "missingSubjs = []\n",
    "\n",
    "for s in FULL_SUBJECT_LIST:\n",
    "    datasource.inputs.subject_id = s\n",
    "    results = datasource.run()\n",
    "    if None not in results.outputs.get().values():\n",
    "        completeSubjs.append(s)\n",
    "    else:\n",
    "        missingSubjs.append(s)\n",
    "print(\"Complete:\",len(completeSubjs),\"MISSING Scans:\",len(missingSubjs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup for Registration  Pipeline InfoSource i.e. subjects\n",
    "\"\"\"\n",
    "subj_infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),  name=\"subj_infosource\")\n",
    "#infosource.iterables = ('subject_id', SampleSubjList)\n",
    "subj_infosource.iterables = ('subject_id', completeSubjs)\n",
    "### Above just converts the list of subjects into an iterable list I can connect to the next part of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RIGID BODY REGISTRATION OF DTI -- >  Struct Brain    using RegSynQuick\n",
    "reg_Struct_to_MNI = mem.cache(RegistrationSynQuick)\n",
    "reg_DTI_to_Struct = mem.cache(RegistrationSynQuick)\n",
    "\n",
    "for subjID in completeSubjs:\n",
    "    subjWD = os.path.join(regScratchDir,str(subjID))\n",
    "    if not os.path.isdir(subjWD):\n",
    "        os.makedirs(subjWD)\n",
    "\n",
    "    ### DTI -->  STRUCT\n",
    "    struct_brain = '/data/HCP_Data/HCP_BedpostData/%s/T1w/T1w_acpc_dc_masked.nii.gz' % subjID\n",
    "    nodif_brain = '/data/HCP_Data/HCP_BedpostData/%s/T1w/Diffusion/nodif_brain.nii.gz' % subjID\n",
    "    MNI_1MM = '/usr/share/fsl/5.0/data/standard/MNI152_T1_1mm_brain.nii.gz'\n",
    "\n",
    "    d_to_s_op= os.path.join(regScratchDir,str(subjID),\"%s_DTI_to_Struct_\" % subjID)\n",
    "    s_to_MNI_1mm_op = os.path.join(regScratchDir,str(subjID),\"%s_Struct_to_MNI_1mm_\" % subjID)\n",
    "    \n",
    "    reg_DTI_to_Struct(moving_image=nodif_brain,fixed_image=struct_brain,num_threads=24,\n",
    "                      transform_type='r',output_prefix=d_to_s_op)\n",
    "    \n",
    "    #### Struct --> MNI\n",
    "    reg_Struct_to_MNI(moving_image=struct_brain,fixed_image=MNI_1MM,num_threads=24,\n",
    "                     output_prefix=s_to_MNI_1mm_op)\n",
    "    \n",
    "    ## TO DO-- COMBINE ROIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg_Struct_to_MNI.inputs.transforms = ['SyN']  ## Mandatory\n",
    "# reg_Struct_to_MNI.inputs.dimension = 3\n",
    "#reg_Struct_to_MNI.inputs.float = False\n",
    "# reg_Struct_to_MNI.inputs.interpolation = 'NearestNeighbor'### or Linear?\n",
    "# reg_Struct_to_MNI.inputs.metric = ['MI']\n",
    "# reg_Struct_to_MNI.inputs.metric_weight = [1.0]\n",
    "# reg_Struct_to_MNI.inputs.smoothing_sigmas = [[3,0]]\n",
    "# reg_Struct_to_MNI.inputs.shrink_factors = [[8,4,2,1]]\n",
    "# reg_Struct_to_MNI.inputs.number_of_iterations= [[10000,10000,10000,10000]]\n",
    "# reg_Struct_to_MNI.inputs.radius_or_number_of_bins=[32]\n",
    "# reg_Struct_to_MNI.inputs.radius_bins_stage_trait=[1]\n",
    "# reg_Struct_to_MNI.inputs.sampling_strategy = ['Regular']\n",
    "# reg_Struct_to_MNI.inputs.sigma_units=['vox']\n",
    "# reg_Struct_to_MNI.inputs.transform_parameters = [(0.25,)]\n",
    "# reg_Struct_to_MNI.inputs.winsorize_lower_quantile = 0.005\n",
    "# reg_Struct_to_MNI.inputs.winsorize_upper_quantile = 0.995\n",
    "# reg_Struct_to_MNI.inputs.use_histogram_matching = False\n",
    "# reg_Struct_to_MNI.inputs.num_threads = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_DTI_to_Struct.cmdline\n",
    "#/usr/lib/ants/ANTS 3 -m PR[MNI152_T1_1mm_brain.nii.gz,T1w_acpc_dc_masked.nii.gz,1,4] \n",
    "# -t SyN[0.25] -r Gauss[3,0] -o T1_to_MNI_ -i 30x90x20 --use-Histogram-Matching \n",
    "# --number-of-affine-iterations 10000x10000x10000x10000x10000 --MI-option 32x16000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wi = result.outputs.warped_image\n",
    "# from niwidgets import NiftiWidget\n",
    "# from niwidgets import examplet1\n",
    "\n",
    "# test_widget = NiftiWidget(wi)\n",
    "# test_widget.nifti_plotter()\n",
    "\n",
    "\n",
    "# fixed_widget = NiftiWidget( \"/data/HCP_Data/HCP_BedpostData/100206/T1w/T1w_acpc_dc_masked.nii.gz\")\n",
    "# fixed_widget.nifti_plotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antsL.antsIntroduction()\n",
    "# ants.WarpImageMultiTransform()\n",
    "run_hcp_reg  = pe.Workflow(name=\"run_hcp_reg\")\n",
    "run_hcp_reg.base_dir = \"/data/HCP_Data/NipypeScratch/\"\n",
    "\n",
    "#samples_base_name_fxn = lambda x : x.replace('_th1samples.nii.gz','')\n",
    "\n",
    "run_hcp_reg.connect(subj_infosource,'subject_id',datasource,'subject_id')\n",
    "# ### Connect the dti_datasource to the pbx2 command\n",
    "run_hcp_reg.connect( datasource,'struct_brain',regDTI_to_Struct,'reference_image')\n",
    "run_hcp_reg.connect( datasource,'nodif_brain',regDTI_to_Struct,'input_image')\n",
    "# runpbx2.connect( datasource,'fsamples',pbx2,'fsamples')\n",
    "# runpbx2.connect( datasource,'nodif_brain_mask',pbx2,'mask')\n",
    "# runpbx2.connect( datasource, ('thsamples', samples_base_name_fxn ), pbx2,'samples_base_name') ###  NOTE THIS IS A WEIRD TUPLE IS\n",
    "\n",
    "#run_hcp_reg.run()\n",
    "run_hcp_reg.run(plugin='MultiProc', plugin_args={'n_procs' : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concepts/Steps\n",
    "\n",
    "## 3 Spaces     DTI    ---- >    T1        --->MNI\n",
    "## DTI is probably \"best\" registered using the nodif_brain which is the first image of the \"data.nii.gz\" file\n",
    "#antsIntroduction.sh -d 3 -r $MNI_BRAIN  -i $T1_BRAIN -o T1_to_MNI_ -t GR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTI='/data/HCP_Data/HCP_BedpostData/100610/T1w/Diffusion/data.nii.gz'\n",
    "# DTI_B0='/data/HCP_Data/HCP_BedpostData/100610/T1w/Diffusion/nodif_brain.nii.gz'\n",
    "# DTI_M='/data/HCP_Data/HCP_BedpostData/100610/T1w/Diffusion/nodif_brain_mask.nii.gz'\n",
    "# T1_M='/data/HCP_Data/HCP_BedpostData/100610/T1w/brainmask_fs.nii.gz'\n",
    "# T1='/data/HCP_Data/HCP_BedpostData/100610/T1w/T1w_acpc_dc.nii.gz'\n",
    "# # DTI_TO_T1='/data/HCP_Data/Scripts/GutmanLabNipypeWorkflows/HCP_Pipelines/sampleAntsRegData/nodif_to_T1_deformed.nii.gz\n",
    "# MNI_BRAIN='/usr/share/fsl/5.0/data/standard/MNI152_T1_1mm_brain.nii.gz'\n",
    "# #T1_BRAIN=''/HCP_Data/Scripts/GutmanLabNipypeWorkflows/HCP_Pipelines/sampleAntsRegData/T1w_acpc_dc_masked.nii.gz\n",
    "# ROI_ONE='/data/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Left.nii.gz' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# echo $IN $T1_M $T1\n",
    "\n",
    "# ## NOTES PROBABLY wouLD bE QUICKER IF WE USED THE T1 IMAGE WIHT THE MASK APPLIED... TO DO!!\n",
    "\n",
    "# export PATH=$PATH:/usr/lib/ants\n",
    "# export ANTSPATH=/usr/lib/ants\n",
    "\n",
    "# ## Get the first B0 image from the DTI data set\n",
    "# #fslroi $DTI $DTI_B0 0 1 \n",
    "\n",
    "\n",
    "# ## Register the B0/DTI image to the T1 --- we perhaps should have used the masked/brainonly T1??\n",
    "# #antsIntroduction.sh -d 3 -r $T1 -i $DTI_B0 -o nodif_to_T1_ -t RI\n",
    "\n",
    "\n",
    "# ## Need to apply the brain mask to the T1 image to speed things up\n",
    "# #fslmaths $T1 -mas $T1_M $T1_MASKED\n",
    "\n",
    "\n",
    "# ### Thsi registers the T1 Brain image nonlinearly to MNI Space.. and also generated the inverse warp\n",
    "# #antsIntroduction.sh -d 3 -r $MNI_BRAIN  -i $T1_BRAIN -o T1_to_MNI_ -t GR\n",
    "\n",
    "# ### note T1_To_MNI_Warp is the warp transform.. and we add two affine matrices which are also real files\n",
    "# #WarpImageMultiTransform 3 $DTI_B0  nodif_to_MNI_test.nii.gz -R $MNI_BRAIN  T1_to_MNI_Warp.nii.gz T1_to_MNI_Affine.txt nodif_to_T1_Affine.txt\n",
    "\n",
    "\n",
    "# ### THIS GOES IN REVERSE\n",
    "# WarpImageMultiTransform 3 $ROI_ONE ROI_ONE_to_subjDTI.nii.gz -R $DTI_B0 -i nodif_to_T1_Affine.txt -i T1_to_MNI_Affine.txt  T1_to_MNI_InverseWarp.nii.gz\n",
    "# WarpImageMultiTransform 3 $ROI_ONE ROI_ONE_to_subjDTI_NN.nii.gz -R $DTI_B0 --use-NN -i nodif_to_T1_Affine.txt -i T1_to_MNI_Affine.txt  T1_to_MNI_InverseWarp.nii.gz\n",
    "\n",
    "# ## --use-NN: Use Nearest Neighbor Interpolation. \n",
    " \n",
    "\n",
    "END PRODUCT:   We will create a directory in Diffusion or maybe ROIs and maybe a subdirectory called DTI\n",
    "    \n",
    "    so /{SubjID}/T1w/ROIs/DTI_Space/Human_L_Hypothalamus.nii\n",
    "       /{SubjID}/xfms/<<PUT XFMS HERE>> \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #\n",
    "# #Then check that nodif-to-MNI mappings look good: slicesdir –p MNI_template.nii.gz Subj_*_nodif_to_MNI.nii.gz\n",
    "# #Apply INVERSE transformation from MNI-space ROIs to individual subjects’ diffusion space\n",
    "# #WarpImageMultiTransform 3 template_ROI.nii.gz SubjX_ROI.nii.gz –R nodif.nii.gz –i DTI_to_T1_Affine.txt –i T1_to_MNI_Affine.txt T1_to_MNI_InverseWarp.nii.gz\n",
    "\n",
    " \n",
    "\n",
    "# #Run probtrackx using native-space ROIs… this will produce a native-space fdt_paths.nii.gz file.  Threshold and normalize in native space.\n",
    "\n",
    " \n",
    "\n",
    "# #Apply transformations to get thresholded, normalized tracts into MNI space\n",
    "\n",
    "# #WarpImageMultiTransform 3 fdt_paths_thresh_norm.nii.gz SubjX_fdt_paths_thresh_norm_in_MNIspace.nii.gz -R MNI.nii.gz T1_to_MNI_Warp.nii.gz T1_to_MNI_Affine.txt DTI_to_T1_Affine.txt\n",
    "\n",
    " \n",
    "\n",
    "# #Fslmerge –t Subj*_fdt_paths_thresh_norm_in_MNIspace.nii.gz à this becomes the input for randomi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with the MNI-space hypothalamus / basal forebrain ROIs à want to end up with tractography in all subjects in MNI space\n",
    "\n",
    " \n",
    "\n",
    "Compute rigid body transform from diffusion space to T1\n",
    "\n",
    "antsIntroduction.sh -d 3 -r T1.nii.gz -i nodif.nii.gz -o nodif_to_T1_ -t RI\n",
    "\n",
    " \n",
    "\n",
    "Compute nonlinear warp from T1 to MNI\n",
    "\n",
    "antsIntroduction.sh -d 3 -r MNI.nii.gz -i T1.nii.gz -o T1_to_MNI_ -t GR\n",
    "\n",
    "(I think GR (greedy Syn) should be faster than SY (Syn) which is the default and apparently I’ve been using GR with good results so far)\n",
    "\n",
    " \n",
    "\n",
    "Apply transformations so you can check that it all looks OK\n",
    "\n",
    "WarpImageMultiTransform 3 nodif.nii.gz nodif_to_MNI.nii.gz -R MNI.nii.gz T1_to_MNI_Warp.nii.gz T1_to_MNI_Affine.txt DTI_to_T1_Affine.txt\n",
    "\n",
    "Then check that nodif-to-MNI mappings look good: slicesdir –p MNI_template.nii.gz Subj_*_nodif_to_MNI.nii.gz\n",
    "\n",
    " \n",
    "\n",
    "Apply INVERSE transformation from MNI-space ROIs to individual subjects’ diffusion space\n",
    "\n",
    "WarpImageMultiTransform 3 template_ROI.nii.gz SubjX_ROI.nii.gz –R nodif.nii.gz –i DTI_to_T1_Affine.txt –i T1_to_MNI_Affine.txt T1_to_MNI_InverseWarp.nii.gz\n",
    "\n",
    " \n",
    "\n",
    "Run probtrackx using native-space ROIs… this will produce a native-space fdt_paths.nii.gz file.  Threshold and normalize in native space.\n",
    "\n",
    " \n",
    "\n",
    "Apply transformations to get thresholded, normalized tracts into MNI space\n",
    "\n",
    "WarpImageMultiTransform 3 fdt_paths_thresh_norm.nii.gz SubjX_fdt_paths_thresh_norm_in_MNIspace.nii.gz -R MNI.nii.gz T1_to_MNI_Warp.nii.gz T1_to_MNI_Affine.txt DTI_to_T1_Affine.txt\n",
    "\n",
    " \n",
    "\n",
    "Fslmerge –t Subj*_fdt_paths_thresh_norm_in_MNIspace.nii.gz à this becomes the input for randomise\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thisfolder=${PWD}/sampleOutput\n",
    "sub=11111 \n",
    "\n",
    "antsRegistration --dimensionality 3 --float 0 \\\n",
    "--output [$thisfolder/NN_DTI_to_Struct_${sub}_,$thisfolder/NN_DTI_to_Struct_${sub}_Warped.nii.gz] \\\n",
    "--interpolation NearestNeighbor \\\n",
    "--winsorize-image-intensities [0.005,0.995] \\\n",
    "--use-histogram-matching 0 \\\n",
    "--transform Rigid[0.1] \\\n",
    "--metric MI[$T1_BRAIN,$DTI_B0,1,32,Regular,0.25] \\\n",
    "--convergence [1000x500x250x100,1e-6,10] \\\n",
    "--shrink-factors 8x4x2x1 \\\n",
    "--smoothing-sigmas 3x2x1x0vox \n",
    "\n",
    "#reg.inputs.convergence_threshold = [1.e-6]\n",
    "#reg.inputs.convergence_window_size = [10]\n",
    "# reg.inputs.use_histogram_matching = False\n",
    "# reg.inputs.winsorize_upper_quantile = 0.995\n",
    "# reg.inputs.winsorize_lower_quantile = 0.005\n",
    "\n",
    "# >>> reg.inputs.metric_weight = [1]*2 # Default (value ignored currently by ANTs)\n",
    "# >>> reg.inputs.radius_or_number_of_bins = [32]*2\n",
    "# >>> reg.inputs.sampling_strategy = ['Random', None]\n",
    "# >>> reg.inputs.sampling_percentage = [0.05, None]\n",
    "# >>> reg.inputs.convergence_window_size = [20]*2\n",
    "# >>> reg.inputs.sigma_units = ['vox'] * 2\n",
    "# >>> reg.inputs.use_estimate_learning_rate_once = [True, True]\n",
    "# >>> reg.inputs.use_histogram_matching = [True, True] # This is the default\n",
    "# >>> reg.inputs.output_warped_image = 'output_warped_image.nii.gz'\n",
    "# >>> reg.inputs.write_composite_transform = True\n",
    "# >>> reg.inputs.collapse_output_transforms = False\n",
    "# >>> reg.inputs.initialize_transforms_per_stage = False\n",
    "\n",
    "# >>> reg.cmdline\n",
    "# 'antsRegistration --collapse-output-transforms 0 --dimensionality 3 --initial-moving-transform [ trans.mat, 0 ] --initialize-transforms-per-stage 0 --interpolation Linear --output [ output_, output_warped_image.nii.gz ] --transform Affine[ 2.0 ] --metric Mattes[ fixed1.nii, moving1.nii, 1, 32, Random, 0.05 ] --convergence [ 1500x200, 1e-\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTI=/HCP_Data/HCP_BedpostData/100610/T1w/Diffusion/data.nii.gz\n",
    "DTI_B0=/HCP_Data/HCP_BedpostData/100610/T1w/Diffusion/nodif_brain.nii.gz\n",
    "DTI_M=/HCP_Data/HCP_BedpostData/100610/T1w/Diffusion/nodif_brain_mask.nii.gz\n",
    "T1_M=/HCP_Data/HCP_BedpostData/100610/T1w/brainmask_fs.nii.gz\n",
    "T1=/HCP_Data/HCP_BedpostData/100610/T1w/T1w_acpc_dc.nii.gz\n",
    "DTI_TO_T1=/HCP_Data/Scripts/GutmanLabNipypeWorkflows/HCP_Pipelines/sampleAntsRegData/nodif_to_T1_deformed.nii.gz\n",
    "MNI_BRAIN=/usr/share/fsl/5.0/data/standard/MNI152_T1_1mm_brain.nii.gz \n",
    "\n",
    "T1_BRAIN=/HCP_Data/Scripts/GutmanLabNipypeWorkflows/HCP_Pipelines/sampleAntsRegData/T1w_acpc_dc_masked.nii.gz\n",
    "\n",
    "ROI_ONE=/HCP_Data/EHECHT_ROIS/Human_Hypothalamus_Left.nii.gz  \n",
    "\n",
    "\n",
    "echo $IN $T1_M $T1\n",
    "\n",
    "## NOTES PROBABLY wouLD bE QUICKER IF WE USED THE T1 IMAGE WIHT THE MASK APPLIED... TO DO!!\n",
    "\n",
    "export PATH=$PATH:/usr/lib/ants\n",
    "export ANTSPATH=/usr/lib/ants\n",
    "\n",
    "## Get the first B0 image from the DTI data set\n",
    "#fslroi $DTI $DTI_B0 0 1 \n",
    "\n",
    "\n",
    "## Register the B0/DTI image to the T1 --- we perhaps should have used the masked/brainonly T1??\n",
    "#antsIntroduction.sh -d 3 -r $T1 i $DTI_B0 -o nodif_to_T1_ -t RI\n",
    "\n",
    "\n",
    "## Need to apply the brain mask to the T1 image to speed things up\n",
    "#fslmaths $T1 -mas $T1_M $T1_MASKED\n",
    "\n",
    "\n",
    "### Thsi registers the T1 Brain image nonlinearly to MNI Space.. and also generated the inverse warp\n",
    "#antsIntroduction.sh -d 3 -r $MNI_BRAIN  -i $T1_BRAIN -o T1_to_MNI_ -t GR\n",
    "\n",
    "### note T1_To_MNI_Warp is the warp transform.. and we add two affine matrices which are also real files\n",
    "#WarpImageMultiTransform 3 $DTI_B0  nodif_to_MNI_test.nii.gz -R $MNI_BRAIN  T1_to_MNI_Warp.nii.gz T1_to_MNI_Affine.txt nodif_to_T1_Affine.txt\n",
    "\n",
    "### THIS GOES IN REVERSE\n",
    "WarpImageMultiTransform 3 $ROI_ONE ROI_ONE_to_subjDTI.nii.gz -R $DTI_B0 -i nodif_to_T1_Affine.txt -i T1_to_MNI_Affine.txt  T1_to_MNI_InverseWarp.nii.gz\n",
    "WarpImageMultiTransform 3 $ROI_ONE ROI_ONE_to_subjDTI_NN.nii.gz -R $DTI_B0 --use-NN -i nodif_to_T1_Affine.txt -i T1_to_MNI_Affine.txt  T1_to_MNI_InverseWarp.nii.gz\n",
    "\n",
    "## --use-NN: Use Nearest Neighbor Interpolation. \n",
    " \n",
    "#\n",
    "#Then check that nodif-to-MNI mappings look good: slicesdir –p MNI_template.nii.gz Subj_*_nodif_to_MNI.nii.gz\n",
    "#Apply INVERSE transformation from MNI-space ROIs to individual subjects’ diffusion space\n",
    "#WarpImageMultiTransform 3 template_ROI.nii.gz SubjX_ROI.nii.gz –R nodif.nii.gz –i DTI_to_T1_Affine.txt –i T1_to_MNI_Affine.txt T1_to_MNI_InverseWarp.nii.gz\n",
    " \n",
    "\n",
    "#Run probtrackx using native-space ROIs… this will produce a native-space fdt_paths.nii.gz file.  Threshold and normalize in native space.\n",
    "\n",
    "\n",
    "#Apply transformations to get thresholded, normalized tracts into MNI space\n",
    "\n",
    "#WarpImageMultiTransform 3 fdt_paths_thresh_norm.nii.gz SubjX_fdt_paths_thresh_norm_in_MNIspace.nii.gz -R MNI.nii.gz T1_to_MNI_Warp.nii.gz T1_to_MNI_Affine.txt DTI_to_T1_Affine.txt\n",
    "\n",
    " \n",
    "\n",
    "#Fslmerge –t Subj*_fdt_paths_thresh_norm_in_MNIspace.nii.gz à this becomes the input for randomi\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

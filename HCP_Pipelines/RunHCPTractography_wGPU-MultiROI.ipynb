{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype\n",
    "import os,glob,sys,shutil\n",
    "import nipype.interfaces.fsl as fsl\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.interfaces.io as nio\n",
    "from IPython.display import Image\n",
    "\n",
    "from nipype import config\n",
    "# cfg = dict(execution={'remove_unnecessary_outputs': False,\n",
    "#                      'keep_inputs': True},\n",
    "#           monitoring={'enabled': True,\n",
    "#                       'sample_frequency': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!probtrackx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1007, 'Subjects are potentially available to be processed!')\n"
     ]
    }
   ],
   "source": [
    "subjRootDir = \"/data/HCP_BedpostData/\"\n",
    "FULL_SUBJECT_LIST = [x for x in os.listdir(subjRootDir) if os.path.isdir( subjRootDir+'/addlInfo/subject/'+x)]\n",
    "print(len(FULL_SUBJECT_LIST),\"Subjects are potentially available to be processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup for Probtrackx2 Computational Pipeline\n",
    "\"\"\"\n",
    "subj_infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),  name=\"subj_infosource\")\n",
    "#infosource.iterables = ('subject_id', SampleSubjList)\n",
    "subj_infosource.iterables = ('subject_id', FULL_SUBJECT_LIST)\n",
    "### Above just converts the list of subjects into an iterable list I can connect to the next part of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Setup for DataGrabber inputs needed for probtrackx2\n",
    "# \"\"\"\n",
    "datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "        outfields=['nodif_brain_mask','xfm','invxfm','thsamples','phsamples','fsamples','mniROIs']),\n",
    "        name='datasource')\n",
    "# create a node to obtain the functional images\n",
    "datasource.inputs.base_directory = \"/data/HCP_BedpostData/\"\n",
    "datasource.inputs.template ='*'\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.field_template = dict(\n",
    "    thsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    fsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    phsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    nodif_brain_mask='%s/T1w/Diffusion.bedpostX/%s.nii*', \n",
    "    xfm='%s/MNINonLinear/xfms/%s.nii*',\n",
    "    invxfm='%s/MNINonLinear/xfms/%s.nii*',\n",
    "    mniROIs='addlInfo/subject/%s/DTI_ROIs/Human_*_wimt.nii.gz'\n",
    "    )\n",
    "\n",
    "datasource.inputs.template_args = dict(\n",
    "             thsamples = [['subject_id','th1samples']],\n",
    "             phsamples =  [['subject_id','ph1samples']],\n",
    "             fsamples =  [['subject_id','f1samples']],\n",
    "             nodif_brain_mask = [['subject_id','nodif_brain_mask']],\n",
    "             xfm = [['subject_id','acpc_dc2standard']],\n",
    "             invxfm = [['subject_id', 'standard2acpc_dc']],\n",
    "            mniROIs=[['subject_id']]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbx2 = pe.MapNode(interface=fsl.ProbTrackX2(), name='pbx2', iterfield=['seed'])\n",
    "pbx2.inputs.c_thresh = 0.2   # -c 0.2   F cutoff\n",
    "pbx2.inputs.n_steps = 2000   # -S 2000\n",
    "pbx2.inputs.step_length = 0.5 # --steplength=0.5\n",
    "pbx2.inputs.n_samples = 25000  # -P 5000\n",
    "pbx2.inputs.opd = True\n",
    "pbx2.inputs.loop_check = True\n",
    "pbx2.inputs.correct_path_distribution = True # -pd  i.e. distance correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180926-16:34:26,991 nipype.workflow INFO:\n",
      "\t Workflow runpbx2_gpu_dtispace settings: ['check', 'execution', 'logging', 'monitoring']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-360cce49193c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mrunpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mniROIs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpbx2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#pbx2 is a mapnode, so it will run each ROI separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#runpbx2.run(plugin='MultiProc', plugin_args={'n_procs' : 1})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrunpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0mexecgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_expanded_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/copy.pyc\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/copy.pyc\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#runpbx.connect(subj_infosource,'subject_id',datasource,'subject_id')\n",
    "runpbx2  = pe.Workflow(name=\"runpbx2_gpu_dtispace\")\n",
    "runpbx2.base_dir = \"/data/NipypeScratch/\"\n",
    "\n",
    "samples_base_name_fxn = lambda x : x.replace('_th1samples.nii.gz','')\n",
    "\n",
    "runpbx2.connect(subj_infosource,'subject_id',datasource,'subject_id')\n",
    "\n",
    "# ### Connect the dti_datasource to the pbx2 command\n",
    "runpbx2.connect( datasource,'thsamples',pbx2,'thsamples')\n",
    "runpbx2.connect( datasource,'phsamples',pbx2,'phsamples')\n",
    "runpbx2.connect( datasource,'fsamples',pbx2,'fsamples')\n",
    "runpbx2.connect( datasource,'nodif_brain_mask',pbx2,'mask')\n",
    "runpbx2.connect( datasource, ('thsamples', samples_base_name_fxn ), pbx2,'samples_base_name') ###  NOTE THIS IS A WEIRD TUPLE IS\n",
    "\n",
    "\n",
    "runpbx2.connect( datasource,'mniROIs', pbx2,'seed')  #pbx2 is a mapnode, so it will run each ROI separately\n",
    "#runpbx2.run(plugin='MultiProc', plugin_args={'n_procs' : 1})\n",
    "runpbx2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphFile = runpbx2.write_graph(graph2use='orig',simple_form=False)\n",
    "#runpbx2.write_graph(graph2use='colored',simple_form=True)\n",
    "## options are flat , exec\n",
    "\n",
    "# [u'orig', u'flat', u'hierarchical', u'exec', u'colored']\n",
    "\n",
    "\n",
    "#Image('/data/NipypeScratch/runpbx2_gpu_dtispace/graph_detailed.png')\n",
    "Image(graphFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Each probtrackx command for the HCP data set was using about 2% of the memory.. it varied from 1.4 --> 2.3\n",
    "\n",
    "### So on this machine, we could probably specify 36 threads... even 40 although that may start getting dicey\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write a data validator that makes sure everything in the datasource actually exists...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pbx2.iterables = ['seed']\n",
    "#pbx2.iterables = (\"seed\", \"datasource.mniROIs\")\n",
    "#pbx2.inputs.lrtarget3= targetMask  ## This is a hack for now\n",
    "#pbx2.inputs.seed = seedMask\n",
    "#pbx2.inputs.omatrix3 = True   # --omatrix3\n",
    "#pbx2.inputs.target3 = targetMask # --target3=$WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_GM.nii.gz \"; \n",
    "# pbx2.inputs.onewaycondition = True # --onewaycondition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mandatory]\n",
    "fsamples: (a list of items which are an existing file name)\n",
    "mask: (an existing file name)\n",
    "        bet binary mask file in diffusion space\n",
    "        flag: -m %s\n",
    "phsamples: (a list of items which are an existing file name)\n",
    "seed: (an existing file name or a list of items which are an existing\n",
    "         file name or a list of items which are a list of from 3 to 3 items\n",
    "         which are an integer (int or long))\n",
    "        seed volume(s), or voxel(s)or freesurfer label file\n",
    "        flag: --seed=%s\n",
    "thsamples: (a list of items which are an existing file name)\n",
    "\n",
    "[Optional]\n",
    "args: (a string)\n",
    "        Additional parameters to the command\n",
    "        flag: %s\n",
    "avoid_mp: (an existing file name)\n",
    "        reject pathways passing through locations given by this mask\n",
    "        flag: --avoid=%s\n",
    "c_thresh: (a float)\n",
    "        curvature threshold - default=0.2\n",
    "        flag: --cthr=%.3f\n",
    "colmask4: (an existing file name)\n",
    "        Mask for columns of matrix4 (default=seed mask)\n",
    "        flag: --colmask4=%s\n",
    "correct_path_distribution: (a boolean)\n",
    "        correct path distribution for the length of the pathways\n",
    "        flag: --pd\n",
    "dist_thresh: (a float)\n",
    "        discards samples shorter than this threshold (in mm - default=0)\n",
    "        flag: --distthresh=%.3f\n",
    "distthresh1: (a float)\n",
    "        Discards samples (in matrix1) shorter than this threshold (in mm -\n",
    "        default=0)\n",
    "        flag: --distthresh1=%.3f\n",
    "distthresh3: (a float)\n",
    "        Discards samples (in matrix3) shorter than this threshold (in mm -\n",
    "        default=0)\n",
    "        flag: --distthresh3=%.3f\n",
    "environ: (a dictionary with keys which are a value of type 'str' and\n",
    "         with values which are a value of type 'str', nipype default value:\n",
    "         {})\n",
    "        Environment variables\n",
    "fibst: (an integer (int or long))\n",
    "        force a starting fibre for tracking - default=1, i.e. first fibre\n",
    "        orientation. Only works if randfib==0\n",
    "        flag: --fibst=%d\n",
    "fopd: (an existing file name)\n",
    "        Other mask for binning tract distribution\n",
    "        flag: --fopd=%s\n",
    "force_dir: (a boolean, nipype default value: True)\n",
    "        use the actual directory name given - i.e. do not add + to make a\n",
    "        new directory\n",
    "        flag: --forcedir\n",
    "ignore_exception: (a boolean, nipype default value: False)\n",
    "        Print an error message instead of throwing an exception in case the\n",
    "        interface fails to run\n",
    "inv_xfm: (a file name)\n",
    "        transformation matrix taking DTI space to seed space (compulsory\n",
    "        when using a warp_field for seeds_to_dti)\n",
    "        flag: --invxfm=%s\n",
    "loop_check: (a boolean)\n",
    "        perform loop_checks on paths - slower, but allows lower curvature\n",
    "        threshold\n",
    "        flag: --loopcheck\n",
    "lrtarget3: (an existing file name)\n",
    "        Column-space mask used for Nxn connectivity matrix\n",
    "        flag: --lrtarget3=%s\n",
    "meshspace: ('caret' or 'freesurfer' or 'first' or 'vox')\n",
    "        Mesh reference space - either \"caret\" (default) or \"freesurfer\" or\n",
    "        \"first\" or \"vox\"\n",
    "        flag: --meshspace=%s\n",
    "mod_euler: (a boolean)\n",
    "        use modified euler streamlining\n",
    "        flag: --modeuler\n",
    "n_samples: (an integer (int or long), nipype default value: 5000)\n",
    "        number of samples - default=5000\n",
    "        flag: --nsamples=%d\n",
    "n_steps: (an integer (int or long))\n",
    "        number of steps per sample - default=2000\n",
    "        flag: --nsteps=%d\n",
    "network: (a boolean)\n",
    "        activate network mode - only keep paths going through at least one\n",
    "        seed mask (required if multiple seed masks)\n",
    "        flag: --network\n",
    "omatrix1: (a boolean)\n",
    "        Output matrix1 - SeedToSeed Connectivity\n",
    "        flag: --omatrix1\n",
    "omatrix2: (a boolean)\n",
    "        Output matrix2 - SeedToLowResMask\n",
    "        flag: --omatrix2\n",
    "        requires: target2\n",
    "omatrix3: (a boolean)\n",
    "        Output matrix3 (NxN connectivity matrix)\n",
    "        flag: --omatrix3\n",
    "        requires: target3, lrtarget3\n",
    "omatrix4: (a boolean)\n",
    "        Output matrix4 - DtiMaskToSeed (special Oxford Sparse Format)\n",
    "        flag: --omatrix4\n",
    "onewaycondition: (a boolean)\n",
    "        Apply waypoint conditions to each half tract separately\n",
    "        flag: --onewaycondition\n",
    "opd: (a boolean, nipype default value: True)\n",
    "        outputs path distributions\n",
    "        flag: --opd\n",
    "os2t: (a boolean)\n",
    "        Outputs seeds to targets\n",
    "        flag: --os2t\n",
    "out_dir: (an existing directory name)\n",
    "        directory to put the final volumes in\n",
    "        flag: --dir=%s\n",
    "output_type: ('NIFTI_PAIR' or 'NIFTI_PAIR_GZ' or 'NIFTI_GZ' or\n",
    "         'NIFTI')\n",
    "        FSL output type\n",
    "rand_fib: (0 or 1 or 2 or 3)\n",
    "        options: 0 - default, 1 - to randomly sample initial fibres (with f\n",
    "        > fibthresh), 2 - to sample in proportion fibres (with f>fibthresh)\n",
    "        to f, 3 - to sample ALL populations at random (even if f<fibthresh)\n",
    "        flag: --randfib=%d\n",
    "random_seed: (a boolean)\n",
    "        random seed\n",
    "        flag: --rseed\n",
    "s2tastext: (a boolean)\n",
    "        output seed-to-target counts as a text file (useful when seeding\n",
    "        from a mesh)\n",
    "        flag: --s2tastext\n",
    "sample_random_points: (a boolean)\n",
    "        sample random points within seed voxels\n",
    "        flag: --sampvox\n",
    "samples_base_name: (a string, nipype default value: merged)\n",
    "        the rootname/base_name for samples files\n",
    "        flag: --samples=%s\n",
    "seed_ref: (an existing file name)\n",
    "        reference vol to define seed space in simple mode - diffusion space\n",
    "        assumed if absent\n",
    "        flag: --seedref=%s\n",
    "simple: (a boolean)\n",
    "        rack from a list of voxels (seed must be a ASCII list of\n",
    "        coordinates)\n",
    "        flag: --simple\n",
    "step_length: (a float)\n",
    "        step_length in mm - default=0.5\n",
    "        flag: --steplength=%.3f\n",
    "stop_mask: (an existing file name)\n",
    "        stop tracking at locations given by this mask file\n",
    "        flag: --stop=%s\n",
    "target2: (an existing file name)\n",
    "        Low resolution binary brain mask for storing connectivity\n",
    "        distribution in matrix2 mode\n",
    "        flag: --target2=%s\n",
    "target3: (an existing file name)\n",
    "        Mask used for NxN connectivity matrix (or Nxn if lrtarget3 is set)\n",
    "        flag: --target3=%s\n",
    "target4: (an existing file name)\n",
    "        Brain mask in DTI space\n",
    "        flag: --target4=%s\n",
    "target_masks: (a list of items which are a file name)\n",
    "        list of target masks - required for seeds_to_targets classification\n",
    "        flag: --targetmasks=%s\n",
    "terminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
    "        Control terminal output: `stream` - displays to terminal immediately\n",
    "        (default), `allatonce` - waits till command is finished to display\n",
    "        output, `file` - writes output to file, `none` - output is ignored\n",
    "use_anisotropy: (a boolean)\n",
    "        use anisotropy to constrain tracking\n",
    "        flag: --usef\n",
    "verbose: (0 or 1 or 2)\n",
    "        Verbose level, [0-2].Level 2 is required to output particle files.\n",
    "        flag: --verbose=%d\n",
    "waycond: ('OR' or 'AND')\n",
    "        Waypoint condition. Either \"AND\" (default) or \"OR\"\n",
    "        flag: --waycond=%s\n",
    "wayorder: (a boolean)\n",
    "        Reject streamlines that do not hit waypoints in given order. Only\n",
    "        valid if waycond=AND\n",
    "        flag: --wayorder\n",
    "waypoints: (an existing file name)\n",
    "        waypoint mask or ascii list of waypoint masks - only keep paths\n",
    "        going through ALL the masks\n",
    "        flag: --waypoints=%s\n",
    "xfm: (an existing file name)\n",
    "        transformation matrix taking seed space to DTI space (either FLIRT\n",
    "        matrix or FNIRT warp_field) - default is identity\n",
    "        flag: --xfm=%s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_infosource = pe.Node(interface=util.IdentityInterface(fields=['mniROIs']),  name=\"roi_infosource\")\n",
    "# #infosource.iterables = ('subject_id', SampleSubjList)\n",
    "# #roi_infosource.iterables = ('subject_id', FULL_SUBJECT_LIST)\n",
    "\n",
    "\n",
    "# roiSplit = pe.Node(interface=util.Split(splits=[1,1,1,1,1,1]),name='roiSplit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runpbx2.connect( dti_datasource, ('thsamples',samples_base_name_fxn) ,pbx2,'samples_base_name')\n",
    "# # Run tractography with warp to/from template space\n",
    "# $statement .= \" -s $WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/merged \"; \n",
    "# $statement .= \" -x $WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_WM.nii.gz \";  ## check downsample\n",
    "# $statement .= \" -l   --fibthresh=0.1 --randfib=0 \";  ## check # of samples\n",
    "# $statement .= \" --forcedir --opd \";\n",
    "# $statement .= \" --dir=$WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/WholeBrainMatrixConnectivity_TemplateSpace_fullres/ \";\n",
    "# print \"$statement \\n\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --pd   correct_path_distribution \n",
    "#-l\n",
    "#-c 0.2    --->> c_thresh\n",
    "#-S 2000   \n",
    "#--steplength=0.5\n",
    "#-P 5000    n_samples\n",
    "#--fibthresh=0.1   \n",
    "#--randfib=0  rand_fib\n",
    "#-s /home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/Subj_026/data.bedpostX/merged \n",
    "#-m /home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/Subj_026/data/nodif_brain_mask.nii.gz\n",
    "#-x /home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/ROIs/Human_BasalForebrain_Left.nii.gz \n",
    "#--target2=/home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/ROIs/MNI152_T1_1mm_brain_mask.nii.gz \n",
    "#--xfm=/home/ehecht/TEMPLETON/Templeton_Registration/xfms/Subj_026_Scan2_MNI_fnirt_struct_6dof-flirt_nodif.nii.gz\n",
    "#--invxfm=/home/ehecht/TEMPLETON/Templeton_Registration/xfms/Subj_026_Scan2_nodif_6dof-flirt_struct_fnirt_MNI.nii.gz \n",
    "#--forcedir \n",
    "#--opd\n",
    "#--dir=/home/ehecht/TEMPLETON/Templeton_DTI_Analysis/Data/Subj_026/BasalForebrain_Left_TemplateSpace/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pbx2.inputs.seed = 'seed_source.nii.gz'\n",
    "# >>> pbx2.inputs.thsamples = 'merged_th1samples.nii.gz'\n",
    "# >>> pbx2.inputs.fsamples = 'merged_f1samples.nii.gz'\n",
    "# >>> pbx2.inputs.phsamples = 'merged_ph1samples.nii.gz'\n",
    "# >>> pbx2.inputs.mask = 'nodif_brain_mask.nii.gz'\n",
    "# >>> pbx2.inputs.out_dir = '.'\n",
    "# >>> pbx2.inputs.n_samples = 3\n",
    "# >>> pbx2.inputs.n_steps = 10\n",
    "# >>> pbx2.cmdline\n",
    "\n",
    "# datasource.inputs.template = '%s/T1w/Diffusion/%s'\n",
    "# datasource.inputs.template_args = dict(dwi=[['subject_id', 'data.nii.gz']],\n",
    "#                                        bvecs=[['subject_id', 'bvecs']],\n",
    "#                                        bvals=[['subject_id', 'bvals']],\n",
    "#                                        nodif_brain_mask=[['subject_id','nodif_brain_mask.nii.gz']])\n",
    "## Just mapped each subject to the corresponding bvec,bvals, brain mask and preprocessed DWI data\n",
    "### Create the Node for DTIFIT\n",
    "# dtifit = pe.Node(interface=fsl.DTIFit(), name='dtifit')\n",
    "\n",
    "\n",
    "# gen_fa = pe.Workflow(name=\"gen_fa\")\n",
    "# gen_fa.base_dir = '/data/HCP_Data/NipypeScratch/'\n",
    "# gen_fa.connect(subject_id_infosource, 'subject_id', datasource, 'subject_id')\n",
    "\n",
    "# gen_fa.connect(subject_id_infosource, 'subject_id', dtifit, 'base_name')\n",
    "# gen_fa.connect(datasource, 'bvecs', dtifit, 'bvecs')\n",
    "# gen_fa.connect(datasource, 'bvals', dtifit, 'bvals')\n",
    "# gen_fa.connect(datasource, 'nodif_brain_mask', dtifit, 'mask')\n",
    "# gen_fa.connect(datasource, 'dwi', dtifit, 'dwi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_fa.write_graph(graph2use='colored',simple_form=False))\n",
    "Image('/data/HCP_Data/NipypeScratch/gen_fa/graph.png')\n",
    "#Image('/data/HCP_Data/NipypeScratch/gen_fa/graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_fa.run(plugin='MultiProc', plugin_args={'n_procs' : 20})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /data/HCP_Data/HCP_BedpostData/106016/T1w/Diffusion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasink = pe.Node(interface=nio.DataSink(), name=\"datasink\")\n",
    "datasink.inputs.base_directory = os.path.join(os.path.abspath(working_data_dir),\n",
    "                                              'sri_results')\n",
    "datasink.inputs.parameterization = False\n",
    "gen_fa.connect(dtifit, 'FA', datasink, 'FA')\n",
    "gen_fa.connect(dtifit, 'MD', datasink, 'MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Setup for DataGrabber inputs needed for probtrackx2\n",
    "# \"\"\"\n",
    "datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],\n",
    "        outfields=['nodif_brain_mask','xfm','invxfm','thsamples','phsamples','fsamples','lhyp',\n",
    "                   'rhyp','hyp','lbf','rbf','bf','mniROIs']),\n",
    "        name='datasource')\n",
    "# create a node to obtain the functional images\n",
    "datasource.inputs.base_directory = \"/data/HCP_BedpostData/\"\n",
    "datasource.inputs.template ='*'\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.field_template = dict(\n",
    "    thsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    fsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    phsamples='%s/T1w/Diffusion.bedpostX/merged_%s.nii*',\n",
    "    nodif_brain_mask='%s/T1w/Diffusion.bedpostX/%s.nii*', \n",
    "    xfm='%s/MNINonLinear/xfms/%s.nii*',\n",
    "    invxfm='%s/MNINonLinear/xfms/%s.nii*',\n",
    "    lhyp='addlInfo/subjContainer/%s/DTI_ROIs/Human_Hypothalamus_Left_wimt.nii.gz',\n",
    "    rhyp='addlInfo/subjContainer/%s/DTI_ROIs/Human_Hypothalamus_Right_wimt.nii.gz',\n",
    "    hyp='addlInfo/subjContainer/%s/DTI_ROIs/Human_Hypothalamus_Bilat_wimt.nii.gz',\n",
    "    lbf='addlInfo/subjContainer/%s/DTI_ROIs/Human_BasalForebrain_Left_wimt.nii.gz',\n",
    "    rbf='addlInfo/subjContainer/%s/DTI_ROIs/Human_BasalForebrain_Right_wimt.nii.gz',\n",
    "    bf='addlInfo/subjContainer/%s/DTI_ROIs/Human_BasalForebrain_Bilat_wimt.nii.gz',\n",
    "    mniROIs='addlInfo/subjContainer/%s/DTI_ROIs/Human_*_wimt.nii.gz'\n",
    "    )\n",
    "\n",
    "# Human_BasalForebrain_Bilat_wimt.nii.gz  Human_BasalForebrain_Right_wimt.nii.gz  Human_Hypothalamus_Left_wimt.nii.gz\n",
    "# Human_BasalForebrain_Left_wimt.nii.gz   Human_Hypothalamus_Bilat_wimt.nii.gz    Human_Hypothalamus_Right_wimt.nii.gz\n",
    "\n",
    "datasource.inputs.template_args = dict(\n",
    "             thsamples = [['subject_id','th1samples']],\n",
    "             phsamples =  [['subject_id','ph1samples']],\n",
    "             fsamples =  [['subject_id','f1samples']],\n",
    "             nodif_brain_mask = [['subject_id','nodif_brain_mask']],\n",
    "             xfm = [['subject_id','acpc_dc2standard']],\n",
    "             invxfm = [['subject_id', 'standard2acpc_dc']],\n",
    "             bf=[['subject_id']], \n",
    "             lbf=[['subject_id']],\n",
    "             rbf=[['subject_id']],\n",
    "             lhyp=[['subject_id']],\n",
    "             rhyp=[['subject_id']],\n",
    "             hyp=[['subject_id']],\n",
    "            mniROIs=[['subject_id']]    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "\n",
    "subjDir = \"/data/HCP_Data/HCP_BedpostData/100206/T1w/Diffusion.bedpostX/\"\n",
    "\n",
    "pbx2 = fsl.ProbTrackX2()\n",
    "pbx2.inputs.seed = '/data/HCP_Data/EHECHT_ROIS/Human_BasalForebrain_Left.nii.gz'\n",
    "pbx2.inputs.thsamples = subjDir + 'merged_th1samples.nii.gz'\n",
    "pbx2.inputs.fsamples =  subjDir + 'merged_f1samples.nii.gz'\n",
    "pbx2.inputs.phsamples =  subjDir + 'merged_ph1samples.nii.gz'\n",
    "pbx2.inputs.mask =  subjDir + 'nodif_brain_mask.nii.gz'\n",
    "pbx2.inputs.out_dir = '.'\n",
    "pbx2.inputs.n_samples = 3\n",
    "pbx2.inputs.n_steps = 10\n",
    "pbx2.cmdline\n",
    "pbx2.run()\n",
    "#'probtrackx2 --forcedir -m nodif_brain_mask.nii.gz --nsamples=3 --nstep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

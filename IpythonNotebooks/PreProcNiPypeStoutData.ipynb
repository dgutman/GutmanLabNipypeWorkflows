{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Nipype Workflow for Erin's DTI Data\n",
    "### Convert RAW DICOM data to NIFTI Image Data set\n",
    "import os, sys\n",
    "from os.path import join as oj\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.utility as util\n",
    "import nipype.interfaces.io as nio\n",
    "import nipype.interfaces.fsl as fsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### This scripts assumes all of the RAW data has already been converted to NIFTI and is dumped into \n",
    "### A Single directory for each subject...\n",
    "StoutHaberNIIData = '/FEATURES/NiPypeWorkingData/StoutHaber/NII_Data_Complete/'\n",
    "NiPypeOutputDir = '/FEATURES/NiPypeWorkingData/StoutHaber/niPypePreProc/'\n",
    "### Add additional PATHS HERE if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 Subjects to process\n"
     ]
    }
   ],
   "source": [
    "HomoFaberImageSessions = os.listdir(StoutHaberNIIData)\n",
    "\n",
    "## LETS BE SMART..\n",
    "StoutSubjectList = []  ### This contains a list of all the ImageSessions with a Complete Data set\n",
    "for ss in HomoFaberImageSessions:\n",
    "    fullSubjDirPath =  oj(StoutHaberNIIData,ss)\n",
    "    if not os.path.isdir(fullSubjDirPath):\n",
    "        print \"UH OH!!! Directory Missing\",fullSubjDirPath\n",
    "    else:\n",
    "        StoutSubjectList.append(ss)\n",
    "print len(StoutSubjectList),\"Subjects to process\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Let's create our preprocessing workflow\n",
    "stoutPreProc_wf = pe.Workflow('stoutPreProc_wf') ## Initialize the workflow\n",
    "stoutPreProc_wf.base_dir = NiPypeOutputDir  ## Tell it where to dump the results of the workflow\n",
    "\n",
    "### Create the list of Subjects to Process\n",
    "imageSession_InfoSrc  = pe.Node(util.IdentityInterface(fields=['imageSessionName']),name='imageSession_InfoSrc')\n",
    "imageSession_InfoSrc.iterables = ('imageSessionName', HomoFaberImageSessions)\n",
    "\n",
    "StoutDataSourceDict = dict(  \n",
    "        T1 = [['imageSessionName',          'T1/struc_raw.nii.gz']],\n",
    "        nodif_PA=[['imageSessionName',      'DTI/preprocess/5B0_PA/nodif_PA.nii.gz']], \n",
    "        nodif_PA_bvec=[['imageSessionName', 'DTI/preprocess/5B0_PA/nodif_PA_bvec']],\n",
    "        nodif_PA_bval=[['imageSessionName', 'DTI/preprocess/5B0_PA/nodif_PA_bval']],\n",
    "        data_AP=[['imageSessionName',       'DTI/preprocess/5B0_PA/nodif_PA.nii.gz']], \n",
    "        data_AP_bval=[['imageSessionName',  'DTI/preprocess/AP/data_AP_bval']],\n",
    "        data_AP_bvec=[['imageSessionName',  'DTI/preprocess/AP/data_AP_bvec']])\n",
    "\n",
    "# ## Create a datasource.. this basically helps me find the individual image files and data sets for an image session\n",
    "# ## a single image directory likely consists of DTI data, T2 images, T1 images, etc, etc\n",
    "datasource = pe.Node(interface=nio.DataGrabber(infields=['imageSessionName'], outfields=StoutDataSourceDict.keys() ), name='datasource') \n",
    "datasource.inputs.base_directory = StoutHaberNIIData\n",
    "datasource.inputs.template = '%s/%s'\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.base_directory = StoutHaberNIIData\n",
    "datasource.inputs.template_args = StoutDataSourceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nipype.interfaces.utility import Function\n",
    "# get AP avg b0\n",
    "\n",
    "### I need to get the B0 images which come out of the FSL split and select the first\n",
    "### several images needed for the average\n",
    "def getB0images( input_files ):\n",
    "    \"\"\"This will return an image stack for merging \"\"\"\n",
    "    import os\n",
    "    b0_Images = []\n",
    "    b0_image_suffixes = [ 'vol0000.nii.gz','vol0001.nii.gz','vol0002.nii.gz','vol0003.nii.gz','vol0004.nii.gz',\n",
    "                          'vol0005.nii.gz','vol0006.nii.gz']\n",
    "    for fwp in input_files: #file w path\n",
    "        if os.path.basename(fwp) in b0_image_suffixes:\n",
    "            b0_Images.append(fwp)  ###means I found one of the b0 image files I wanted\n",
    "    return b0_Images  ### List of images to merge\n",
    "   \n",
    "getB0images_interface = Function(input_names=[\"input_files\"], output_names=[\"b0_image_list\"], function=getB0images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def getDiffimages( input_files ):  \n",
    "#     \"\"\"This will return an image stack for merging \"\"\"\n",
    "#     import os\n",
    "#     b0_Images = []\n",
    "#     b0_image_suffixes = [ 'vol0000.nii.gz','vol0001.nii.gz','vol0002.nii.gz','vol0003.nii.gz','vol0004.nii.gz',\n",
    "#                           'vol0005.nii.gz','vol0006.nii.gz']\n",
    "#     for fwp in input_files: #file w path\n",
    "#         if os.path.basename(fwp) in b0_image_suffixes:\n",
    "#             b0_Images.append(fwp)  ###means I found one of the b0 image files I wanted\n",
    "#     return b0_Images  ### List of images to merge\n",
    "   \n",
    "# getB0images_interface = Function(input_names=[\"input_files\"], output_names=[\"b0_image_list\"], function=getB0images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_AP = pe.Node(fsl.Split(dimension='t'), name='split_AP')\n",
    "get_B0_images = pe.Node(interface=getB0images_interface, name='get_B0_images' )\n",
    "merge_AP_B0 = pe.Node(fsl.Merge(dimension='t'), name='merge_AP_B0')\n",
    "average_AP_B0 = pe.Node(fsl.MeanImage(dimension='t'), name='average_AP_B0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Process the PA Images as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoutPreProc_wf.connect(imageSession_InfoSrc,'imageSessionName', datasource, 'imageSessionName')\n",
    "stoutPreProc_wf.connect(datasource,'data_AP',split_AP,'in_file')\n",
    "stoutPreProc_wf.connect(split_AP,'out_files', get_B0_images, 'input_files')\n",
    "stoutPreProc_wf.connect(get_B0_images,'b0_image_list', merge_AP_B0, 'in_files')\n",
    "stoutPreProc_wf.connect(merge_AP_B0,'merged_file', average_AP_B0, 'out_file')  ## Average the merged AP B0 files\n",
    "\n",
    "\n",
    "#average_AP_B0 = pe.Node(fsl.MeanImage(dimension='t'), name='average_AP_B0')\n",
    "\n",
    "#stoutPreProc_wf.connect(get_B0_images,'b0_image_list', get_B0_images, 'input_files')\n",
    "#stoutPreProc_wf.connect(split_AP,'out_files', merge_AP_B0,'in_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/IPython/kernel/__init__.py:13: ShimWarning: The `IPython.kernel` package has been deprecated. You should import from ipykernel or jupyter_client instead.\n",
      "  \"You should import from ipykernel or jupyter_client instead.\", ShimWarning)\n",
      "/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/IPython/parallel.py:13: ShimWarning: The `IPython.parallel` package has been deprecated. You should import from ipyparallel instead.\n",
      "  \"You should import from ipyparallel instead.\", ShimWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170111-22:12:32,729 workflow INFO:\n",
      "\t ['check', 'execution', 'logging']\n",
      "170111-22:12:32,835 workflow INFO:\n",
      "\t Running in parallel.\n",
      "170111-22:12:32,844 workflow INFO:\n",
      "\t Submitting 1 jobs\n",
      "170111-22:12:32,845 workflow INFO:\n",
      "\t Executing: datasource ID: 0\n",
      "170111-22:12:32,864 workflow INFO:\n",
      "\t Executing node datasource in dir: /FEATURES/NiPypeWorkingData/StoutHaber/niPypePreProc/stoutPreProc_wf/datasource\n",
      "170111-22:13:32,920 workflow ERROR:\n",
      "\t ['Node datasource failed to run on host oppenheimer.']\n",
      "170111-22:13:32,923 workflow INFO:\n",
      "\t Saving crash info to /home/dgutman/devel/GutmanLabNipypeWorkflows/IpythonNotebooks/crash-20170111-221332-dgutman-datasource.pklz\n",
      "170111-22:13:32,925 workflow INFO:\n",
      "\t Traceback (most recent call last):\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/plugins/multiproc.py\", line 18, in run_node\n",
      "    result['result'] = node.run(updatehash=updatehash)\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/engine.py\", line 1428, in run\n",
      "    self._run_interface()\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/engine.py\", line 1538, in _run_interface\n",
      "    self._result = self._run_command(execute)\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/engine.py\", line 1664, in _run_command\n",
      "    result = self._interface.run()\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1034, in run\n",
      "    outputs = self.aggregate_outputs(runtime)\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/interfaces/base.py\", line 1105, in aggregate_outputs\n",
      "    predicted_outputs = self._list_outputs()\n",
      "  File \"/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/interfaces/io.py\", line 500, in _list_outputs\n",
      "    raise ValueError(msg)\n",
      "ValueError: DataGrabber requires a value for input 'imageSessionName' because it was listed in 'infields'\n",
      "Interface DataGrabber failed to run. \n",
      "\n",
      "170111-22:14:32,995 workflow INFO:\n",
      "\t ***********************************\n",
      "170111-22:14:32,998 workflow ERROR:\n",
      "\t could not run node: stoutPreProc_wf.datasource\n",
      "170111-22:14:33,3 workflow INFO:\n",
      "\t crashfile: /home/dgutman/devel/GutmanLabNipypeWorkflows/IpythonNotebooks/crash-20170111-221332-dgutman-datasource.pklz\n",
      "170111-22:14:33,5 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a352275915a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstoutPreProc_wf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MultiProc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'n_procs'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/engine.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'poll_sleep_duration'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remove_node_dirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaskid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dgutman/anaconda/envs/dag_nipype/lib/python2.7/site-packages/nipype/pipeline/plugins/base.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     90\u001b[0m                             'Check log for details'))\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "stoutPreProc_wf.run(plugin='MultiProc', plugin_args={'n_procs' : 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MeanImage  #### Take the Mean Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SplitME = fsl.Split(dimension='t')\n",
    "# SplitME.inputs.in_file = '/FEATURES/NiPypeWorkingData/StoutHaber/NII_Data_Complete/Subj01_Scan1/DTI/preprocess/AP/data_AP.nii.gz'\n",
    "# result = SplitME.run()\n",
    "# print result.outputs.out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  http://nipype.readthedocs.io/en/latest/interfaces/generated/nipype.interfaces.fsl.maths.html#meanimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "$volSTRING=\"07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
    " 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9\n",
    "4 95 96 97\";\n",
    "@vol = split(/ /,$volSTRING);\n",
    "\n",
    "$roiSTRING=\"IFG-vPrCG\";\n",
    "@roi = split(/ /,$roiSTRING);\n",
    "\n",
    "$hemiSTRING=\"L R\";\n",
    "@hemi = split(/ /,$hemiSTRING);\n",
    "\n",
    "# run topup first, then feed topup output into eddy (the new eddy, not the old eddy_correct)\n",
    "\n",
    "    \n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol -t \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslmaths $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0000.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0001.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0002.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0003.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0004.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0005.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol0006.nii.gz \";\n",
    "$statement .= \" -div 7 $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/avg_b0_AP.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "# get PA avg b0\n",
    "$statement  = \" fslsplit $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/nodif_PA.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/vol -t \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslmaths $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/vol0000.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/vol0001.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/vol0002.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/vol0003.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/5B0_PA/vol0004.nii.gz \";\n",
    "$statement .= \" -div 5 $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/5B0_PA/avg_b0_PA.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "# get AP dti\n",
    "$x=0;\n",
    "$statement  = \" fslmerge -t $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/dti_AP.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol00\" . $vol[$x] . \".nii.gz \";\n",
    "for($x=1;$x<=$#vol;$x++)        {\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/vol00\" . $vol[$x] . \".nii.gz \";\n",
    "                                }\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslroi $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/dti_AP.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/dti_AP_trim.nii.gz \";\n",
    "$statement .= \" 0 -1 0 -1 0 110 \";\n",
    "#print \"$statement \\n\"; # topup needs an even # of slices\n",
    "\n",
    "    \n",
    "\n",
    "# make merged avg b0\n",
    "$statement  = \" fslmerge -t $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/avg_b0_AP.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/5B0_PA/avg_b0_PA.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslroi $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA_trim.nii.gz \";\n",
    "$statement .= \" 0 -1 0 -1 0 110 \";\n",
    "#print \"$statement \\n\";  # topup needs an even # of slices\n",
    "$statement  = \" fslmerge -t $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA_dti_trim.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA_trim.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/dti_AP_trim.nii.gz \";\n",
    "#print \"$statement \\n\";  # will be input for eddy\n",
    "\n",
    "# topup unwarping\n",
    "$statement  = \" topup \";\n",
    "$statement .= \" --imain=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA_trim.nii.gz \";\n",
    "$statement .= \" --datain=$WORKINGDATAPATH/acq_params.txt \";\n",
    "$statement .= \" --config=/usr/share/fsl/5.0/etc/flirtsch/b02b0.cnf \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/topup \";\n",
    "$statement .= \" --fout=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/topup_fieldmap \"; # can be used for FEAT\n",
    "$statement .= \" --iout=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_unwarped.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" applytopup \";\n",
    "$statement .= \" --method=jac \"; # because dti images are only acquired in AP direction; not merging AP+PA\n",
    "$statement .= \" --imain=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/preprocess/AP/dti_AP_trim.nii.gz \";\n",
    "$statement .= \" --inindex=1 \"; # because in the merged_b0_AP-PA file used to drive topup, the AP data is first\n",
    "$statement .= \" --datain=$WORKINGDATAPATH/acq_params.txt \";\n",
    "$statement .= \" --topup=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/topup \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/dti_unwarped.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "    \n",
    "\n",
    "# make data, nodif, and nodif_brain_mask\n",
    "$statement  = \" fslsplit $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_unwarped.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_unwarped_vol -t \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslmaths $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_unwarped_vol0000 \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_unwarped_vol0001 \";\n",
    "$statement .= \" -div 2 $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" bet $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif_brain \";\n",
    "$statement .= \" -m -f 0.3 -R\";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fast -B -g -t 2 -o $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" mv $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_seg_0.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_GM.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" mv $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_seg_1.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_WM.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "# eddy\n",
    "$statement  = \" eddy \";\n",
    "$statement .= \" --imain=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/merged_b0_AP-PA_dti_trim.nii.gz \";\n",
    "$statement .= \" --mask=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "$statement .= \" --index=$WORKINGDATAPATH/eddy_index.txt \";\n",
    "$statement .= \" --acqp=$WORKINGDATAPATH/acq_params.txt \";\n",
    "$statement .= \" --topup=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/preprocess/topup \";\n",
    "$statement .= \" --bvecs=$WORKINGDATAPATH/eddy_bvecs \";\n",
    "$statement .= \" --bvals=$WORKINGDATAPATH/eddy_bvals \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data_eddy \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslroi \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data_eddy.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif1.nii.gz \";\n",
    "$statement .= \" 0 1 \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslroi \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data_eddy.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif2.nii.gz \";\n",
    "    \n",
    "$statement .= \" 1 1 \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslmaths $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif1.nii.gz \";\n",
    "$statement .= \" -add $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif2.nii.gz \";\n",
    "$statement .= \" -div 2 $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslroi \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data_eddy.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data_dti.nii.gz \";\n",
    "$statement .= \" 2 91 \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fslmerge -t $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data_dti.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "    # dtifit\n",
    "$statement  = \" dtifit \";\n",
    "$statement .= \" -k $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data.nii.gz \";\n",
    "$statement .= \" -o $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/data \";\n",
    "$statement .= \" -m $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "$statement .= \" -r $WORKINGDATAPATH/bvecs \";\n",
    "$statement .= \" -b $WORKINGDATAPATH/bvals \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "# bedpost\n",
    "$statement  = \" cp $WORKINGDATAPATH/bvecs \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/bvecs \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" cp $WORKINGDATAPATH/bvals \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/bvals \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" bedpostx $WORKINGDATAPATH/\" .$subj[$i] . \"/DTI/data/\";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "# T1 preprocessing\n",
    "$statement  = \" fslreorient2std $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_raw.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_raw.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" bet $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_raw.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain \";\n",
    "$statement .= \" -m -f 0.4 -g -0.1 -B \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" fast -B -g -o $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" mv $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain_restore.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" mv $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain_seg_1.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain_GM.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "$statement  = \" mv $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain_seg_2.nii.gz \";\n",
    "$statement .= \" $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain_WM.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "    \n",
    "\n",
    "## REGISTRATION\n",
    "\n",
    "$statement  = \" mkdir $WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/ \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" flirt -dof 12 -in $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "$statement .= \" -ref $WORKINGDATAPATH/MNI152_T1_1mm_brain.nii.gz \";\n",
    "$statement .= \" -omat $WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_MNI.mat \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" fnirt --in=$WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_raw.nii.gz \";\n",
    "$statement .= \" --ref=$WORKINGDATAPATH/MNI152_T1_1mm.nii.gz \";\n",
    "$statement .= \" --aff=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_MNI.mat \";\n",
    "$statement .= \" --cout=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" applywarp --in=$WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "$statement .= \" --ref=$WORKINGDATAPATH/MNI152_T1_1mm.nii.gz \";\n",
    "$statement .= \" --warp=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_2_MNI.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" invwarp --warp=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "$statement .= \" --ref=$WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_warpfield.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" flirt -dof 12 -in $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain.nii.gz \";\n",
    "$statement .= \" -ref $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "$statement .= \" -omat $WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" flirt -in $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain.nii.gz \";\n",
    "$statement .= \" -ref $WORKINGDATAPATH/\" . $subj[$i] . \"/T1/struc_brain.nii.gz \";\n",
    "$statement .= \" -applyxfm -init $WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "$statement .= \" -out $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_2_struc.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" applywarp --in=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain.nii.gz \";\n",
    "$statement .= \" --ref=$WORKINGDATAPATH/MNI152_T1_1mm.nii.gz \";\n",
    "$statement .= \" --premat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "\n",
    "    $statement .= \" --warp=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_2_MNI.nii.gz \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" convert_xfm \";\n",
    "$statement .= \" -omat $WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_nodif.mat \";\n",
    "$statement .= \" -inverse $WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "#print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" convertwarp \";\n",
    "$statement .= \" --ref=$WORKINGDATAPATH/MNI152_T1_1mm_brain.nii.gz \";\n",
    "$statement .= \" --premat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "$statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc_warp_MNI_warpfield.nii.gz \";\n",
    "print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" convertwarp \";\n",
    "$statement .= \" --ref=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "$statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_warpfield.nii.gz \";\n",
    "$statement .= \" --postmat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_nodif.mat \";\n",
    "$statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_12dof_nodif_warpfield.nii.gz \";\n",
    "print \"$statement \\n\";\n",
    "\n",
    "$statement  = \" probtrackx2 --pd --onewaycondition --omatrix2 \";\n",
    "$statement .= \" -s $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data.bedpostX/merged \";\n",
    "$statement .= \" -m $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "$statement .= \" -x $WORKINGDATAPATH/ROIs/Human_\" . $roi[$r] . \"_\" . $hemi[$h] . \".nii.gz \";\n",
    "$statement .= \" --target2=$WORKINGDATAPATH/MNI152_T1_1mm_brain_mask_downsample_2.nii.gz \";\n",
    "$statement .= \" -l -c 0.2 -S 2000 --steplength=0.5 -P 5000 --fibthresh=0.1 --randfib=0 \";  # check samples\n",
    "$statement .= \" --xfm=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_12dof_nodif_warpfield.nii.gz \";\n",
    "$statement .= \" --invxfm=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc_warp_MNI_warpfield.nii.gz \";\n",
    "$statement .= \" --forcedir --opd \";\n",
    "$statement .= \" --dir=$OUTPUTDATAPATH/\" . $subj[$i] . \"_\" . $roi[$r] . \"_\" . $hemi[$h] . \"_Segmentation  \";\n",
    "print \"$statement \\n\";\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

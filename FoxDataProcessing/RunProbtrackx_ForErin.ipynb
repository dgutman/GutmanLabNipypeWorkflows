{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nipype.interfaces.io as nio  # Data i/o\n",
    "import nipype.interfaces.fsl as fsl  # fsl\n",
    "import nipype.interfaces.utility as util  # utility\n",
    "import nipype.pipeline.engine as pe # pipeline engine\n",
    "from glob import glob\n",
    "from os.path import join as oj\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 Directories with Fox_ detected\n"
     ]
    }
   ],
   "source": [
    "FoxDataBaseDir = \"/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/\"\n",
    "\n",
    "subject_list = [x for x in os.listdir(FoxDataBaseDir) if x.startswith(\"Fox_\")]\n",
    "print len(subject_list),\"Directories with Fox_ detected\"\n",
    "\n",
    "## These are Erin Generated masks for white and gray matter targets in common space\n",
    "seedMask =   '/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_GM.nii.gz'\n",
    "targetMask = '/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup for Probtrackx2 Computational Pipeline\n",
    "\"\"\"\n",
    "infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),  name=\"infosource\")\n",
    "infosource.iterables = ('subject_id', subject_list[0:2])\n",
    "### Above just converts the list of subjects into an iterable list I can connect to the next part of the pipeline\n",
    "\n",
    "info = dict(\n",
    "             thsamples = [['subject_id','th1samples']],\n",
    "             phsamples =  [['subject_id','ph1samples']],\n",
    "             fsamples =  [['subject_id','f1samples']]   ,\n",
    "             nodif_brain_mask = [['subject_id','nodif_brain_mask']],\n",
    "             xfm = [['subject_id','Unselected-Template_FNIRT-warpfield_T2.nii.gz']],\n",
    "             invxfm = [['subject_id', 'T2_FNIRT-warpfield_Unselected-Template.nii.gz' ]]\n",
    "            \n",
    ")\n",
    "### Generate the files/names for the DTI/bedpostX data\n",
    "dti_datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'], outfields=info.keys() ),   name='dti_datasource')\n",
    "dti_datasource.inputs.base_directory = FoxDataBaseDir\n",
    "dti_datasource.inputs.template = \"*\"\n",
    "dti_datasource.inputs.sort_filelist=True\n",
    "dti_datasource.inputs.field_template = dict( \n",
    "    nodif_brain_mask = '%s/data.bedpostX/%s.nii.gz',    \n",
    "    thsamples='%s/data.bedpostX/merged_%s.nii.gz',\n",
    "    phsamples='%s/data.bedpostX/merged_%s.nii.gz',\n",
    "    fsamples='%s/data.bedpostX/merged_%s.nii.gz',\n",
    "    xfm = \"%s/xfms/%s\",\n",
    "    invxfm = \"%s/xfms/%s\"\n",
    ")\n",
    "dti_datasource.inputs.template_args = info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d54f502f4e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpbx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProbTrackX2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pbx2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# probtrackx.inputs.mode = 'seedmask'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m   \u001b[0;31m# -c 0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2000\u001b[0m   \u001b[0;31m# -S 2000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;31m# --steplength=0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pe' is not defined"
     ]
    }
   ],
   "source": [
    "pbx2 = pe.Node(interface=fsl.ProbTrackX2(), name='pbx2')\n",
    "# probtrackx.inputs.mode = 'seedmask'\n",
    "pbx2.inputs.c_thresh = 0.2   # -c 0.2\n",
    "pbx2.inputs.n_steps = 2000   # -S 2000\n",
    "pbx2.inputs.step_length = 0.5 # --steplength=0.5\n",
    "pbx2.inputs.n_samples = 5000 # -P 5000\n",
    "pbx2.inputs.opd = True\n",
    "pbx2.inputs.os2t = True\n",
    "pbx2.inputs.loop_check = True\n",
    "pbx2.inputs.onewaycondition = True # --onewaycondition\n",
    "pbx2.inputs.omatrix3 = True   # --omatrix3\n",
    "pbx2.inputs.target3 = targetMask # --target3=$WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_GM.nii.gz \"; \n",
    "pbx2.inputs.correct_path_distribution = True # -pd\n",
    "pbx2.inputs.seed = seedMask\n",
    "\n",
    "pbx2.inputs.samples_base_name = 'merged'\n",
    "\n",
    "pbx2.inputs.lrtarget3= targetMask  ## This is a hack for now\n",
    "\n",
    "# # Run tractography with warp to/from template space\n",
    "# $statement .= \" -s $WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/merged \"; \n",
    "# $statement .= \" -x $WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_WM.nii.gz \";  ## check downsample\n",
    "# $statement .= \" -l   --fibthresh=0.1 --randfib=0 \";  ## check # of samples\n",
    "# $statement .= \" --forcedir --opd \";\n",
    "# $statement .= \" --dir=$WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/WholeBrainMatrixConnectivity_TemplateSpace_fullres/ \";\n",
    "# print \"$statement \\n\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runpbx2  = pe.Workflow(name=\"runpbx2\")\n",
    "runpbx2.base_dir = \"/NIPYPE_SCRATCH/\"\n",
    "\n",
    "runpbx2.connect(infosource,'subject_id',dti_datasource,'subject_id')\n",
    "\n",
    "\n",
    "# samples_base_name_fxn = lambda x : x[0].replace('_th1samples.nii.gz','')\n",
    "\n",
    "\n",
    "# ### Connect the dti_datasource to the pbx2 command\n",
    "runpbx2.connect( dti_datasource,'thsamples',pbx2,'thsamples')\n",
    "runpbx2.connect( dti_datasource,'phsamples',pbx2,'phsamples')\n",
    "runpbx2.connect( dti_datasource,'fsamples',pbx2,'fsamples')\n",
    "runpbx2.connect( dti_datasource,'nodif_brain_mask',pbx2,'mask')\n",
    "# runpbx2.connect( dti_datasource, ('thsamples',samples_base_name_fxn) ,pbx2,'samples_base_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180426-17:48:04,183 workflow INFO:\n",
      "\t Workflow runpbx2 settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "180426-17:48:04,209 workflow INFO:\n",
      "\t Running serially.\n",
      "180426-17:48:04,210 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.dti_datasource\" in \"/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_10T/dti_datasource\".\n",
      "180426-17:48:04,232 workflow INFO:\n",
      "\t [Node] Running \"dti_datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "180426-17:48:04,250 workflow INFO:\n",
      "\t [Node] Finished \"runpbx2.dti_datasource\".\n",
      "180426-17:48:04,252 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_10T/pbx2\".\n",
      "180426-17:48:04,290 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck --lrtarget3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz -m /home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Fox_10T/data.bedpostX/nodif_brain_mask.nii.gz --nsamples=5000 --nsteps=2000 --omatrix3 --onewaycondition --opd --os2t --dir=/home/dgutman/devel/GutmanLabNipypeWorkflows/FoxDataProcessing --samples=merged --seed=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_GM.nii.gz --steplength=0.500 --target3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz\n",
      "180426-17:48:04,322 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:04.322764:Log directory is: /NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_10T/pbx2\n",
      "180426-17:48:04,324 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:04.324362:Running in seedmask mode\n",
      "180426-17:48:04,368 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:04.368608:load seeds\n",
      "180426-17:48:04,769 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:04.769768:done.\n",
      "180426-17:48:04,808 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:04.808422:Load bedpostx samples\n",
      "180426-17:48:04,810 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:04.810176:1_1\n",
      "180426-17:48:09,805 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:09.805167:1_2\n",
      "180426-17:48:14,265 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:14.265000:1_3\n",
      "180426-17:48:18,714 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.714597:\n",
      "180426-17:48:18,715 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.714597:nfibres  : 1\n",
      "180426-17:48:18,716 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.714597:nsamples : 50\n",
      "180426-17:48:18,717 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.714597:\n",
      "180426-17:48:18,718 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.714597:Done loading samples.\n",
      "180426-17:48:18,745 interface INFO:\n",
      "\t stderr 2018-04-26T17:48:18.745769: does not exist\n",
      "180426-17:48:18,806 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_10T/pbx2)\n",
      "180426-17:48:18,819 workflow ERROR:\n",
      "\t Node pbx2.a0 failed to run on host whorlwind.\n",
      "180426-17:48:18,820 workflow ERROR:\n",
      "\t Saving crash info to /home/dgutman/devel/GutmanLabNipypeWorkflows/FoxDataProcessing/crash-20180426-174818-dgutman-pbx2.a0-57b0efee-34c5-45ca-9acb-9d92f6f85560.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 479, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 563, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 642, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 516, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/interfaces/fsl/dti.py\", line 773, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 960, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck --lrtarget3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz -m /home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Fox_10T/data.bedpostX/nodif_brain_mask.nii.gz --nsamples=5000 --nsteps=2000 --omatrix3 --onewaycondition --opd --os2t --dir=/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_10T/pbx2 --samples=merged --seed=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_GM.nii.gz --steplength=0.500 --target3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz\n",
      "Standard output:\n",
      "Log directory is: /NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_10T/pbx2\n",
      "Running in seedmask mode\n",
      "load seeds\n",
      "done.\n",
      "Load bedpostx samples\n",
      "1_1\n",
      "1_2\n",
      "1_3\n",
      "\n",
      "nfibres  : 1\n",
      "nsamples : 50\n",
      "\n",
      "Done loading samples.\n",
      "Standard error:\n",
      " does not exist\n",
      "Return code: 0\n",
      "\n",
      "180426-17:48:18,833 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.dti_datasource\" in \"/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_11T/dti_datasource\".\n",
      "180426-17:48:18,853 workflow INFO:\n",
      "\t [Node] Running \"dti_datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "180426-17:48:18,871 workflow INFO:\n",
      "\t [Node] Finished \"runpbx2.dti_datasource\".\n",
      "180426-17:48:18,873 workflow INFO:\n",
      "\t [Node] Setting-up \"runpbx2.pbx2\" in \"/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_11T/pbx2\".\n",
      "180426-17:48:18,909 workflow INFO:\n",
      "\t [Node] Running \"pbx2\" (\"nipype.interfaces.fsl.dti.ProbTrackX2\"), a CommandLine Interface with command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck --lrtarget3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz -m /home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Fox_11T/data.bedpostX/nodif_brain_mask.nii.gz --nsamples=5000 --nsteps=2000 --omatrix3 --onewaycondition --opd --os2t --dir=/home/dgutman/devel/GutmanLabNipypeWorkflows/FoxDataProcessing --samples=merged --seed=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_GM.nii.gz --steplength=0.500 --target3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz\n",
      "180426-17:48:18,939 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.939520:Log directory is: /NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_11T/pbx2\n",
      "180426-17:48:18,941 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.941192:Running in seedmask mode\n",
      "180426-17:48:18,982 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:18.982138:load seeds\n",
      "180426-17:48:19,351 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:19.350920:done.\n",
      "180426-17:48:19,386 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:19.386567:Load bedpostx samples\n",
      "180426-17:48:19,387 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:19.387666:1_1\n",
      "180426-17:48:24,54 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:24.054799:1_2\n",
      "180426-17:48:28,425 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:28.425477:1_3\n",
      "180426-17:48:32,841 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:32.841162:\n",
      "180426-17:48:32,842 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:32.841162:nfibres  : 1\n",
      "180426-17:48:32,843 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:32.841162:nsamples : 50\n",
      "180426-17:48:32,844 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:32.841162:\n",
      "180426-17:48:32,844 interface INFO:\n",
      "\t stdout 2018-04-26T17:48:32.841162:Done loading samples.\n",
      "180426-17:48:32,870 interface INFO:\n",
      "\t stderr 2018-04-26T17:48:32.870133: does not exist\n",
      "180426-17:48:32,927 workflow WARNING:\n",
      "\t [Node] Error on \"runpbx2.pbx2\" (/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_11T/pbx2)\n",
      "180426-17:48:32,940 workflow ERROR:\n",
      "\t Node pbx2.a1 failed to run on host whorlwind.\n",
      "180426-17:48:32,941 workflow ERROR:\n",
      "\t Saving crash info to /home/dgutman/devel/GutmanLabNipypeWorkflows/FoxDataProcessing/crash-20180426-174832-dgutman-pbx2.a1-2e055e22-1b93-4aac-af52-9df040b6a3b6.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.py\", line 44, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 479, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 563, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/nodes.py\", line 642, in _run_command\n",
      "    result = self._interface.run(cwd=outdir)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 516, in run\n",
      "    runtime = self._run_interface(runtime)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/interfaces/fsl/dti.py\", line 773, in _run_interface\n",
      "    self.raise_exception(runtime)\n",
      "  File \"/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/interfaces/base/core.py\", line 960, in raise_exception\n",
      "    ).format(**runtime.dictcopy()))\n",
      "RuntimeError: Command:\n",
      "probtrackx2 --cthr=0.200 --pd --forcedir --loopcheck --lrtarget3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz -m /home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Fox_11T/data.bedpostX/nodif_brain_mask.nii.gz --nsamples=5000 --nsteps=2000 --omatrix3 --onewaycondition --opd --os2t --dir=/NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_11T/pbx2 --samples=merged --seed=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_GM.nii.gz --steplength=0.500 --target3=/home/dgutman/POST_MORTEM_FOXES/POST_MORTEM_FOXES/Probtrack_Targets/All_Foxes_FA_to_Unselected-Template_WM.nii.gz\n",
      "Standard output:\n",
      "Log directory is: /NIPYPE_SCRATCH/runpbx2/_subject_id_Fox_11T/pbx2\n",
      "Running in seedmask mode\n",
      "load seeds\n",
      "done.\n",
      "Load bedpostx samples\n",
      "1_1\n",
      "1_2\n",
      "1_3\n",
      "\n",
      "nfibres  : 1\n",
      "nsamples : 50\n",
      "\n",
      "Done loading samples.\n",
      "Standard error:\n",
      " does not exist\n",
      "Return code: 0\n",
      "\n",
      "180426-17:48:32,953 workflow INFO:\n",
      "\t ***********************************\n",
      "180426-17:48:32,954 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.a0\n",
      "180426-17:48:32,955 workflow INFO:\n",
      "\t crashfile: /home/dgutman/devel/GutmanLabNipypeWorkflows/FoxDataProcessing/crash-20180426-174818-dgutman-pbx2.a0-57b0efee-34c5-45ca-9acb-9d92f6f85560.pklz\n",
      "180426-17:48:32,956 workflow ERROR:\n",
      "\t could not run node: runpbx2.pbx2.a1\n",
      "180426-17:48:32,957 workflow INFO:\n",
      "\t crashfile: /home/dgutman/devel/GutmanLabNipypeWorkflows/FoxDataProcessing/crash-20180426-174832-dgutman-pbx2.a1-2e055e22-1b93-4aac-af52-9df040b6a3b6.pklz\n",
      "180426-17:48:32,957 workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Workflow did not execute cleanly. Check log for details",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-20c273313c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunpbx2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/engine/workflows.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'create_report'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_report_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdatehash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdatehash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0mdatestr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%dT%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr2bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'execution'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'write_provenance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/plugins/linear.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mreport_nodes_not_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dgutman/miniconda2/envs/NiPype/lib/python2.7/site-packages/nipype/pipeline/plugins/tools.pyc\u001b[0m in \u001b[0;36mreport_nodes_not_run\u001b[0;34m(notrun)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"***********************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         raise RuntimeError(('Workflow did not execute cleanly. '\n\u001b[0m\u001b[1;32m     79\u001b[0m                             'Check log for details'))\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Workflow did not execute cleanly. Check log for details"
     ]
    }
   ],
   "source": [
    "runpbx2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# from nipype.interfaces import fsl\n",
    "# pbx2 = fsl.ProbTrackX2()\n",
    "#  pbx2.inputs.seed = 'seed_source.nii.gz'\n",
    "# >>> pbx2.inputs.thsamples = 'merged_th1samples.nii.gz'\n",
    "# >>> pbx2.inputs.fsamples = 'merged_f1samples.nii.gz'\n",
    "# >>> pbx2.inputs.phsamples = 'merged_ph1samples.nii.gz'\n",
    "# >>> pbx2.inputs.mask = 'nodif_brain_mask.nii.gz'\n",
    "# >>> pbx2.inputs.out_dir = '.'\n",
    "# >>> pbx2.inputs.n_samples = 3\n",
    "# >>> pbx2.inputs.n_steps = 10\n",
    "# >>> pbx2.cmdline\n",
    "# 'probtrackx2 --forcedir -m nodif_brain_mask.nii.gz --nsamples=3 --nsteps=10 --opd --dir=. --samples=merged --seed=seed_source.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # runpbx2.connect(\n",
    "# #      [(infosource, datasource, [('subject_id', 'subject_id')]),\n",
    "    \n",
    "    \n",
    "    \n",
    "# #     [(bedpostx, probtrackx,\n",
    "# #                        [('outputnode.thsamples',\n",
    "# #                          'thsamples'), ('outputnode.phsamples', 'phsamples'),\n",
    "# #                         ('outputnode.fsamples', 'fsamples')]),\n",
    "# #                       (probtrackx, findthebiggest, [('targets', 'in_files')]),\n",
    "# #                       (flirt, probtrackx, [('out_matrix_file', 'xfm')])])\n",
    "# \"\"\"\n",
    "# Setup data storage area\n",
    "# \"\"\"\n",
    "\n",
    "# datasink = pe.Node(interface=nio.DataSink(), name='datasink')\n",
    "# datasink.inputs.base_directory = os.path.abspath('dtiresults')\n",
    "\n",
    "\n",
    "# dwiproc.base_dir = os.path.abspath('fsl_dti_tutorial')\n",
    "# dwiproc.connect(\n",
    "#     [(infosource, datasource, [('subject_id', 'subject_id')]),\n",
    "#      (datasource, computeTensor,\n",
    "#       [('dwi', 'fslroi.in_file'), ('bvals', 'dtifit.bvals'),\n",
    "#        ('bvecs', 'dtifit.bvecs'), ('dwi', 'eddycorrect.inputnode.in_file')]),\n",
    "#      (datasource, tractography,\n",
    "#       [('bvals', 'bedpostx.inputnode.bvals'),\n",
    "#        ('bvecs', 'bedpostx.inputnode.bvecs'), ('seed_file', 'probtrackx.seed'),\n",
    "#        ('target_masks', 'probtrackx.target_masks')]),\n",
    "#      (computeTensor, tractography,\n",
    "#       [('eddycorrect.outputnode.eddy_corrected', 'bedpostx.inputnode.dwi'),\n",
    "#        ('bet.mask_file', 'bedpostx.inputnode.mask'), ('bet.mask_file',\n",
    "#                                                       'probtrackx.mask'),\n",
    "#        ('fslroi.roi_file', 'flirt.reference')]), (infosource, datasink, [\n",
    "#            ('subject_id', 'container'), (('subject_id', getstripdir),\n",
    "#                                          'strip_dir')\n",
    "#        ]), (tractography, datasink, [('findthebiggest.out_file',\n",
    "#                                       'fbiggest.@biggestsegmentation')])])\n",
    "\n",
    "\n",
    "# stout_tractography.connect( dti_datasource, 'nodif_brain_mask', cvtwarp_dti_to_mni, 'reference')\n",
    "# stout_tractography.connect( dti_datasource, 'MNI_to_struct', cvtwarp_dti_to_mni, 'warp1')\n",
    "# stout_tractography.connect( dti_datasource, 'struct_to_nodif_aff', cvtwarp_dti_to_mni, 'postmat')\n",
    "\n",
    "      \n",
    "      # #PERFORM PROBALISTIC TRACTOGRAPHY\n",
    "\n",
    "# pbx2 = pe.Node(interface=fsl.ProbTrackX2(),name='pbx2')\n",
    "# pbx2.inputs.c_thresh = 0.2\n",
    "# pbx2.inputs.n_steps=2000\n",
    "# pbx2.inputs.step_length=0.5\n",
    "# pbx2.inputs.n_samples= 5000 ### Make n_samples an iterable field...\n",
    "# pbx2.inputs.opd=True\n",
    "# pbx2.inputs.loop_check=True\n",
    "# pbx2.inputs.omatrix2=True  ##This requires I include target2\n",
    "# pbx2.inputs.correct_path_distribution=True ##corresponds to the --pd flag\n",
    "# pbx2.inputs.onewaycondition=True  \n",
    "# pbx2.inputs.target2= os.path.join(RAWDATAPATH,\"MNI152_T1_1mm_brain_mask_downsample_2.nii.gz\")\n",
    "# pbx2.inputs.rand_fib=0\n",
    "\n",
    "# ### This will eventually become an iterable\n",
    "# pbx2.inputs.seed= [os.path.join(RAWDATAPATH,\"ROIs/Human_IFG-vPrCG_L.nii.gz\"),os.path.join(RAWDATAPATH,\"ROIs/Human_IFG-vPrCG_R.nii.gz\")]\n",
    "\n",
    "# ### Now connect the warps generated from the previous steps\n",
    "\n",
    "# stout_tractography.connect( cvtwarp_dti_to_mni, 'out_file',pbx2,'xfm')\n",
    "# stout_tractography.connect( cvtwarp_mni_to_dti, 'out_file',pbx2,'inv_xfm')\n",
    "\n",
    "# # preuss_tractography.connect( roi_datasource, 'seed_rois',probtrackx,'seed')\n",
    "# #preuss_tractography.connect( seed_mask_ds,'out_files',probtrackx,'seed')\n",
    "# #preuss_tractography.connect( dti_dti_datasource, ('subject_id',mask_info),probtrackx,'seed')\n",
    "\n",
    "# \"\"\"\n",
    "# Setup data storage area for results\n",
    "# \"\"\"\n",
    "# datasink = pe.Node(interface=nio.DataSink(),name='datasink')\n",
    "\n",
    "# stout_tractography.connect( pbx2, 'fdt_paths', datasink, 'fdt_paths')\n",
    "# stout_tractography.connect( pbx2, 'matrix1_dot', datasink, 'matrix1.txt')\n",
    "# stout_tractography.connect( pbx2, 'matrix2_dot', datasink, 'matrix2.txt')\n",
    "# stout_tractography.connect( pbx2, 'matrix3_dot', datasink, 'matrix3.txt')\n",
    "# stout_tractography.connect( pbx2, 'lookup_tractspace', datasink, 'lookup_ts')\n",
    "# stout_tractography.connect( pbx2, 'way_total', datasink, 'waytotal.txt')\n",
    "\n",
    "\n",
    "# #datasink.inputs.base_directory = put_cleaned_up_results_here\n",
    "# #datasink.inputs.substitutions = [('_subject_id_', ''),\n",
    "# #                                 ('_seed_..bigdata2..NIPYPE_WD..SANCHEZ_WD..', '')]\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     stout_tractography.write_graph(format='eps')\n",
    "#     #stout_tractography.export_graph()\n",
    "#     # stout_tractography.run(plugin='MultiProc', plugin_args={'n_procs': 28})\n",
    "#     #dwiproc.run(plugin='PBS', plugin_args = dict(qsub_args='-k oe -q batch ') )\n",
    "#     stout_tractography.run(plugin='PBS', plugin_args=dict(qsub_args='-e trq_logs -o trq_logs -q batch '))\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# ###WORKINGDATAPATH\n",
    "\n",
    "# # $statement  = \" convertwarp \";\n",
    "# # $statement .= \" --ref=$WORKINGDATAPATH/MNI152_T1_1mm_brain.nii.gz \";\n",
    "# # $statement .= \" --premat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "# # $statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "# # $statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc_warp_MNI_warpfield.nii.gz \";\n",
    "# # print \"$statement \\n\";\n",
    "\n",
    "# # $statement  = \" convertwarp \";\n",
    "# # $statement .= \" --ref=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "# # $statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_warpfield.nii.gz \";\n",
    "# # $statement .= \" --postmat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_nodif.mat \";\n",
    "# # $statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_12dof_nodif_warpfield.nii.gz \";\n",
    "# # print \"$statement \\n\";\n",
    "\n",
    "# # print \"$statement \\n\";\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def getstripdir(subject_id):\n",
    "    import os\n",
    "    return os.path.join(\n",
    "        os.path.abspath('data/workingdir/dwiproc'),\n",
    "        '_subject_id_%s' % subject_id)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[Mandatory]\n",
    "fsamples: (a list of items which are an existing file name)\n",
    "mask: (an existing file name)\n",
    "        bet binary mask file in diffusion space\n",
    "        flag: -m %s\n",
    "phsamples: (a list of items which are an existing file name)\n",
    "seed: (an existing file name or a list of items which are an existing\n",
    "         file name or a list of items which are a list of from 3 to 3 items\n",
    "         which are an integer (int or long))\n",
    "        seed volume(s), or voxel(s) or freesurfer label file\n",
    "        flag: --seed=%s\n",
    "thsamples: (a list of items which are an existing file name)\n",
    "\n",
    "[Optional]\n",
    "args: (a unicode string)\n",
    "        Additional parameters to the command\n",
    "        flag: %s\n",
    "avoid_mp: (an existing file name)\n",
    "        reject pathways passing through locations given by this mask\n",
    "        flag: --avoid=%s\n",
    "c_thresh: (a float)\n",
    "        curvature threshold - default=0.2\n",
    "        flag: --cthr=%.3f\n",
    "colmask4: (an existing file name)\n",
    "        Mask for columns of matrix4 (default=seed mask)\n",
    "        flag: --colmask4=%s\n",
    "correct_path_distribution: (a boolean)\n",
    "        correct path distribution for the length of the pathways\n",
    "        flag: --pd\n",
    "dist_thresh: (a float)\n",
    "        discards samples shorter than this threshold (in mm - default=0)\n",
    "        flag: --distthresh=%.3f\n",
    "distthresh1: (a float)\n",
    "        Discards samples (in matrix1) shorter than this threshold (in mm -\n",
    "        default=0)\n",
    "        flag: --distthresh1=%.3f\n",
    "distthresh3: (a float)\n",
    "        Discards samples (in matrix3) shorter than this threshold (in mm -\n",
    "        default=0)\n",
    "        flag: --distthresh3=%.3f\n",
    "environ: (a dictionary with keys which are a bytes or None or a value\n",
    "         of class 'str' and with values which are a bytes or None or a value\n",
    "         of class 'str', nipype default value: {})\n",
    "        Environment variables\n",
    "fibst: (an integer (int or long))\n",
    "        force a starting fibre for tracking - default=1, i.e. first fibre\n",
    "        orientation. Only works if randfib==0\n",
    "        flag: --fibst=%d\n",
    "fopd: (an existing file name)\n",
    "        Other mask for binning tract distribution\n",
    "        flag: --fopd=%s\n",
    "force_dir: (a boolean, nipype default value: True)\n",
    "        use the actual directory name given - i.e. do not add + to make a\n",
    "        new directory\n",
    "        flag: --forcedir\n",
    "ignore_exception: (a boolean, nipype default value: False)\n",
    "        Print an error message instead of throwing an exception in case the\n",
    "        interface fails to run\n",
    "inv_xfm: (a file name)\n",
    "        transformation matrix taking DTI space to seed space (compulsory\n",
    "        when using a warp_field for seeds_to_dti)\n",
    "        flag: --invxfm=%s\n",
    "loop_check: (a boolean)\n",
    "        perform loop_checks on paths - slower, but allows lower curvature\n",
    "        threshold\n",
    "        flag: --loopcheck\n",
    "lrtarget3: (an existing file name)\n",
    "        Column-space mask used for Nxn connectivity matrix\n",
    "        flag: --lrtarget3=%s\n",
    "meshspace: ('caret' or 'freesurfer' or 'first' or 'vox')\n",
    "        Mesh reference space - either \"caret\" (default) or \"freesurfer\" or\n",
    "        \"first\" or \"vox\"\n",
    "        flag: --meshspace=%s\n",
    "mod_euler: (a boolean)\n",
    "        use modified euler streamlining\n",
    "        flag: --modeuler\n",
    "n_samples: (an integer (int or long), nipype default value: 5000)\n",
    "        number of samples - default=5000\n",
    "        flag: --nsamples=%d\n",
    "n_steps: (an integer (int or long))\n",
    "        number of steps per sample - default=2000\n",
    "        flag: --nsteps=%d\n",
    "network: (a boolean)\n",
    "        activate network mode - only keep paths going through at least one\n",
    "        seed mask (required if multiple seed masks)\n",
    "        flag: --network\n",
    "omatrix1: (a boolean)\n",
    "        Output matrix1 - SeedToSeed Connectivity\n",
    "        flag: --omatrix1\n",
    "omatrix2: (a boolean)\n",
    "        Output matrix2 - SeedToLowResMask\n",
    "        flag: --omatrix2\n",
    "        requires: target2\n",
    "omatrix3: (a boolean)\n",
    "        Output matrix3 (NxN connectivity matrix)\n",
    "        flag: --omatrix3\n",
    "        requires: target3, lrtarget3\n",
    "omatrix4: (a boolean)\n",
    "        Output matrix4 - DtiMaskToSeed (special Oxford Sparse Format)\n",
    "        flag: --omatrix4\n",
    "onewaycondition: (a boolean)\n",
    "        Apply waypoint conditions to each half tract separately\n",
    "        flag: --onewaycondition\n",
    "opd: (a boolean, nipype default value: True)\n",
    "        outputs path distributions\n",
    "        flag: --opd\n",
    "os2t: (a boolean)\n",
    "        Outputs seeds to targets\n",
    "        flag: --os2t\n",
    "out_dir: (an existing directory name)\n",
    "        directory to put the final volumes in\n",
    "        flag: --dir=%s\n",
    "output_type: ('NIFTI_PAIR_GZ' or 'NIFTI' or 'NIFTI_GZ' or\n",
    "         'NIFTI_PAIR')\n",
    "        FSL output type\n",
    "rand_fib: (0 or 1 or 2 or 3)\n",
    "        options: 0 - default, 1 - to randomly sample initial fibres (with f\n",
    "        > fibthresh), 2 - to sample in proportion fibres (with f>fibthresh)\n",
    "        to f, 3 - to sample ALL populations at random (even if f<fibthresh)\n",
    "        flag: --randfib=%d\n",
    "random_seed: (a boolean)\n",
    "        random seed\n",
    "        flag: --rseed\n",
    "s2tastext: (a boolean)\n",
    "        output seed-to-target counts as a text file (useful when seeding\n",
    "        from a mesh)\n",
    "        flag: --s2tastext\n",
    "sample_random_points: (a boolean)\n",
    "        sample random points within seed voxels\n",
    "        flag: --sampvox\n",
    "samples_base_name: (a unicode string, nipype default value: merged)\n",
    "        the rootname/base_name for samples files\n",
    "        flag: --samples=%s\n",
    "seed_ref: (an existing file name)\n",
    "        reference vol to define seed space in simple mode - diffusion space\n",
    "        assumed if absent\n",
    "        flag: --seedref=%s\n",
    "simple: (a boolean)\n",
    "        rack from a list of voxels (seed must be a ASCII list of\n",
    "        coordinates)\n",
    "        flag: --simple\n",
    "step_length: (a float)\n",
    "        step_length in mm - default=0.5\n",
    "        flag: --steplength=%.3f\n",
    "stop_mask: (an existing file name)\n",
    "        stop tracking at locations given by this mask file\n",
    "        flag: --stop=%s\n",
    "target2: (an existing file name)\n",
    "        Low resolution binary brain mask for storing connectivity\n",
    "        distribution in matrix2 mode\n",
    "        flag: --target2=%s\n",
    "target3: (an existing file name)\n",
    "        Mask used for NxN connectivity matrix (or Nxn if lrtarget3 is set)\n",
    "        flag: --target3=%s\n",
    "target4: (an existing file name)\n",
    "        Brain mask in DTI space\n",
    "        flag: --target4=%s\n",
    "target_masks: (a list of items which are a file name)\n",
    "        list of target masks - required for seeds_to_targets classification\n",
    "        flag: --targetmasks=%s\n",
    "terminal_output: ('stream' or 'allatonce' or 'file' or 'none')\n",
    "        Control terminal output: `stream` - displays to terminal immediately\n",
    "        (default), `allatonce` - waits till command is finished to display\n",
    "        output, `file` - writes output to file, `none` - output is ignored\n",
    "use_anisotropy: (a boolean)\n",
    "        use anisotropy to constrain tracking\n",
    "        flag: --usef\n",
    "verbose: (0 or 1 or 2)\n",
    "        Verbose level, [0-2]. Level 2 is required to output particle files.\n",
    "        flag: --verbose=%d\n",
    "waycond: ('OR' or 'AND')\n",
    "        Waypoint condition. Either \"AND\" (default) or \"OR\"\n",
    "        flag: --waycond=%s\n",
    "wayorder: (a boolean)\n",
    "        Reject streamlines that do not hit waypoints in given order. Only\n",
    "        valid if waycond=AND\n",
    "        flag: --wayorder\n",
    "waypoints: (an existing file name)\n",
    "        waypoint mask or ascii list of waypoint masks - only keep paths\n",
    "        going through ALL the masks\n",
    "        flag: --waypoints=%s\n",
    "xfm: (an existing file name)\n",
    "        transformation matrix taking seed space to DTI space (either FLIRT\n",
    "        matrix or FNIRT warp_field) - default is identity\n",
    "        flag: --xfm=%s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nipype.pipelinepeline as pe\n",
    "\n",
    "\n",
    "# #!/usr/bin/perl\n",
    "\n",
    "# $WORKINGDATAPATH = \"/home/ehecht/POST_MORTEM_FOXES/\";\n",
    "\n",
    "# $subjSTRING=\"13U 14U 15U 16U 17U 18U 20U 22U 23U 24U 10T 11T 12T 2T 3T 4T 5T 7T 8T 9T 49A 50A 51A 52A 54A 56A 57A 58A 59A 60A\";  \n",
    "# @subj = split(/ /,$subjSTRING);\n",
    "\n",
    "# $dsSTRING=\"0.9\"; #1.5\n",
    "# @ds = split(/ /,$dsSTRING);\n",
    "\n",
    "# $splitSTRING=\"0-440 441-881 882-1322 1323-1764\"; \n",
    "# @split = split(/ /,$splitSTRING);\n",
    "\n",
    "# for($k=0;$k<=$#subj;$k++) \t\t{\n",
    "# for($d=0;$d<=$#ds;$d++) \t\t{\n",
    "\n",
    "# print \"#\\$ -cwd\\n\";\n",
    "# print \"#\\$ -S /bin/bash \\n\";\n",
    "# print \"export FSLDIR=/usr/local/fsl  \\n\";\n",
    "# print \". /usr/local/fsl/etc/fslconf/fsl.sh \\n\";\n",
    "# print \"export PATH=\\$PATH:\\$FSLDIR/bin \\n\";\n",
    "# print \"#!/bin/bash \\n\";\n",
    "\n",
    "# # Run tractography with warp to/from template space\n",
    "# $statement  = \" probtrackx2 --pd --onewaycondition --omatrix3 \";\n",
    "# $statement .= \" -s $WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/merged \"; \n",
    "# $statement .= \" -m $WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/nodif_brain_mask.nii.gz \";\n",
    "# $statement .= \" -x $WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_WM.nii.gz \";  ## check downsample\n",
    "# $statement .= \" --target3=$WORKINGDATAPATH/All_Foxes_FA_to_Unselected-Template_GM.nii.gz \";  ## check downsample\n",
    "# $statement .= \" --xfm=$WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/xfms/Unselected-Template_FNIRT-warpfield_T2.nii.gz \";\n",
    "# $statement .= \" --invxfm=$WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/xfms/T2_FNIRT-warpfield_Unselected-Template.nii.gz \";\n",
    "# $statement .= \" -l -c 0.2 -S 2000 --steplength=0.5 -P 5000 --fibthresh=0.1 --randfib=0 \";  ## check # of samples\n",
    "# $statement .= \" --forcedir --opd \";\n",
    "# $statement .= \" --dir=$WORKINGDATAPATH/Fox_\" . $subj[$k] . \"/data.bedpostX/WholeBrainMatrixConnectivity_TemplateSpace_fullres/ \";\n",
    "# print \"$statement \\n\";\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# >>> from nipype.interfaces import fsl\n",
    "# >>> pbx2 = fsl.ProbTrackX2()\n",
    "# >>> pbx2.inputs.seed = 'seed_source.nii.gz'\n",
    "# >>> pbx2.inputs.thsamples = 'merged_th1samples.nii.gz'\n",
    "# >>> pbx2.inputs.fsamples = 'merged_f1samples.nii.gz'\n",
    "# >>> pbx2.inputs.phsamples = 'merged_ph1samples.nii.gz'\n",
    "# >>> pbx2.inputs.mask = 'nodif_brain_mask.nii.gz'\n",
    "# >>> pbx2.inputs.out_dir = '.'\n",
    "# >>> pbx2.inputs.n_samples = 3\n",
    "# >>> pbx2.inputs.n_steps = 10\n",
    "# >>> pbx2.cmdline\n",
    "# 'probtrackx2 --forcedir -m nodif_brain_mask.nii.gz --nsamples=3 --nsteps=10 --opd --dir=. --samples=merged --seed=seed_source.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "==============\n",
    "dMRI: DTI, FSL\n",
    "==============\n",
    "A pipeline example that uses several interfaces to perform analysis on\n",
    "diffusion weighted images using FSL FDT tools.\n",
    "This tutorial is based on the 2010 FSL course and uses data freely available at\n",
    "the FSL website at: http://www.fmrib.ox.ac.uk/fslcourse/fsl_course_data2.tar.gz\n",
    "More details can be found at\n",
    "http://www.fmrib.ox.ac.uk/fslcourse/lectures/practicals/fdt/index.htm\n",
    "In order to run this tutorial you need to have fsl tools installed and\n",
    "accessible from matlab/command line. Check by calling fslinfo from the command\n",
    "line.\n",
    "Tell python where to find the appropriate functions.\n",
    "\"\"\"\n",
    "\n",
    "import nipype.interfaces.io as nio  # Data i/o\n",
    "import nipype.interfaces.fsl as fsl  # fsl\n",
    "import nipype.interfaces.utility as util  # utility\n",
    "import nipype.pipeline.engine as pe  # pypeline engine\n",
    "import os  # system functions\n",
    "from nipype.workflows.dmri.fsl.dti import create_eddy_correct_pipeline,\\\n",
    "    create_bedpostx_pipeline\n",
    "\"\"\"\n",
    "Confirm package dependencies are installed.  (This is only for the\n",
    "tutorial, rarely would you put this in your own code.)\n",
    "\"\"\"\n",
    "\n",
    "from nipype.utils.misc import package_check\n",
    "\n",
    "package_check('numpy', '1.3', 'tutorial1')\n",
    "package_check('scipy', '0.7', 'tutorial1')\n",
    "package_check('IPython', '0.10', 'tutorial1')\n",
    "\"\"\"\n",
    "Setting up workflows\n",
    "--------------------\n",
    "This is a generic workflow for DTI data analysis using the FSL\n",
    "Data specific components\n",
    "------------------------\n",
    "The nipype tutorial contains data for two subjects.  Subject data is in two\n",
    "subdirectories, ``dwis1`` and ``dwis2``.  Each subject directory contains each\n",
    "of the following files: bvec, bval, diffusion weighted data, a set of target\n",
    "masks, a seed file, and a transformation matrix.\n",
    "Below we set some variables to inform the ``datasource`` about the\n",
    "layout of our data.  We specify the location of the data, the subject\n",
    "sub-directories and a dictionary that maps each run to a mnemonic (or\n",
    "field) for the run type (``dwi`` or ``bvals``).  These fields become\n",
    "the output fields of the ``datasource`` node in the pipeline.\n",
    "Specify the subject directories\n",
    "\"\"\"\n",
    "\n",
    "subject_list = ['subj1']\n",
    "\"\"\"\n",
    "Map field names to individual subject runs\n",
    "\"\"\"\n",
    "\n",
    "info = dict(\n",
    "    dwi=[['subject_id', 'data']],\n",
    "    bvecs=[['subject_id', 'bvecs']],\n",
    "    bvals=[['subject_id', 'bvals']],\n",
    "    seed_file=[['subject_id', 'MASK_average_thal_right']],\n",
    "    target_masks=[[\n",
    "        'subject_id', [\n",
    "            'MASK_average_M1_right', 'MASK_average_S1_right',\n",
    "            'MASK_average_occipital_right', 'MASK_average_pfc_right',\n",
    "            'MASK_average_pmc_right', 'MASK_average_ppc_right',\n",
    "            'MASK_average_temporal_right'\n",
    "        ]\n",
    "    ]])\n",
    "\n",
    "infosource = pe.Node(\n",
    "    interface=util.IdentityInterface(fields=['subject_id']), name=\"infosource\")\n",
    "\"\"\"\n",
    "Here we set up iteration over all the subjects. The following line\n",
    "is a particular example of the flexibility of the system.  The\n",
    "``datasource`` attribute ``iterables`` tells the pipeline engine that\n",
    "it should repeat the analysis on each of the items in the\n",
    "``subject_list``. In the current example, the entire first level\n",
    "preprocessing and estimation will be repeated for each subject\n",
    "contained in subject_list.\n",
    "\"\"\"\n",
    "\n",
    "infosource.iterables = ('subject_id', subject_list)\n",
    "\"\"\"\n",
    "Now we create a :class:`nipype.interfaces.io.DataGrabber` object and\n",
    "fill in the information from above about the layout of our data.  The\n",
    ":class:`nipype.pipeline.engine.Node` module wraps the interface object\n",
    "and provides additional housekeeping and pipeline specific\n",
    "functionality.\n",
    "\"\"\"\n",
    "\n",
    "datasource = pe.Node(\n",
    "    interface=nio.DataGrabber(\n",
    "        infields=['subject_id'], outfields=list(info.keys())),\n",
    "    name='datasource')\n",
    "\n",
    "datasource.inputs.template = \"%s/%s\"\n",
    "\n",
    "# This needs to point to the fdt folder you can find after extracting\n",
    "# http://www.fmrib.ox.ac.uk/fslcourse/fsl_course_data2.tar.gz\n",
    "datasource.inputs.base_directory = os.path.abspath('fsl_course_data/fdt/')\n",
    "\n",
    "datasource.inputs.field_template = dict(\n",
    "    dwi='%s/%s.nii.gz',\n",
    "    seed_file=\"%s.bedpostX/%s.nii.gz\",\n",
    "    target_masks=\"%s.bedpostX/%s.nii.gz\")\n",
    "datasource.inputs.template_args = info\n",
    "datasource.inputs.sort_filelist = True\n",
    "\"\"\"\n",
    "Setup for Diffusion Tensor Computation\n",
    "--------------------------------------\n",
    "Here we will create a generic workflow for DTI computation\n",
    "\"\"\"\n",
    "\n",
    "computeTensor = pe.Workflow(name='computeTensor')\n",
    "\"\"\"\n",
    "extract the volume with b=0 (nodif_brain)\n",
    "\"\"\"\n",
    "\n",
    "fslroi = pe.Node(interface=fsl.ExtractROI(), name='fslroi')\n",
    "fslroi.inputs.t_min = 0\n",
    "fslroi.inputs.t_size = 1\n",
    "\"\"\"\n",
    "create a brain mask from the nodif_brain\n",
    "\"\"\"\n",
    "\n",
    "bet = pe.Node(interface=fsl.BET(), name='bet')\n",
    "bet.inputs.mask = True\n",
    "bet.inputs.frac = 0.34\n",
    "\"\"\"\n",
    "correct the diffusion weighted images for eddy_currents\n",
    "\"\"\"\n",
    "\n",
    "eddycorrect = create_eddy_correct_pipeline('eddycorrect')\n",
    "eddycorrect.inputs.inputnode.ref_num = 0\n",
    "\"\"\"\n",
    "compute the diffusion tensor in each voxel\n",
    "\"\"\"\n",
    "\n",
    "dtifit = pe.Node(interface=fsl.DTIFit(), name='dtifit')\n",
    "\"\"\"\n",
    "connect all the nodes for this workflow\n",
    "\"\"\"\n",
    "\n",
    "computeTensor.connect(\n",
    "    [(fslroi, bet, [('roi_file', 'in_file')]),\n",
    "     (eddycorrect, dtifit, [('outputnode.eddy_corrected', 'dwi')]),\n",
    "     (infosource, dtifit,\n",
    "      [['subject_id', 'base_name']]), (bet, dtifit, [('mask_file', 'mask')])])\n",
    "\"\"\"\n",
    "Setup for Tracktography\n",
    "-----------------------\n",
    "Here we will create a workflow to enable probabilistic tracktography\n",
    "and hard segmentation of the seed region\n",
    "\"\"\"\n",
    "\n",
    "tractography = pe.Workflow(name='tractography')\n",
    "tractography.base_dir = os.path.abspath('fsl_dti_tutorial')\n",
    "\"\"\"\n",
    "estimate the diffusion parameters: phi, theta, and so on\n",
    "\"\"\"\n",
    "\n",
    "bedpostx = create_bedpostx_pipeline()\n",
    "bedpostx.get_node(\"xfibres\").iterables = (\"n_fibres\", [1, 2])\n",
    "\n",
    "flirt = pe.Node(interface=fsl.FLIRT(), name='flirt')\n",
    "flirt.inputs.in_file = fsl.Info.standard_image('MNI152_T1_2mm_brain.nii.gz')\n",
    "flirt.inputs.dof = 12\n",
    "\"\"\"\n",
    "perform probabilistic tracktography\n",
    "\"\"\"\n",
    "\n",
    "probtrackx = pe.Node(interface=fsl.ProbTrackX(), name='probtrackx')\n",
    "probtrackx.inputs.mode = 'seedmask'\n",
    "probtrackx.inputs.c_thresh = 0.2\n",
    "probtrackx.inputs.n_steps = 2000\n",
    "probtrackx.inputs.step_length = 0.5\n",
    "probtrackx.inputs.n_samples = 5000\n",
    "probtrackx.inputs.opd = True\n",
    "probtrackx.inputs.os2t = True\n",
    "probtrackx.inputs.loop_check = True\n",
    "\"\"\"\n",
    "perform hard segmentation on the output of probtrackx\n",
    "\"\"\"\n",
    "\n",
    "findthebiggest = pe.Node(interface=fsl.FindTheBiggest(), name='findthebiggest')\n",
    "\"\"\"\n",
    "connect all the nodes for this workflow\n",
    "\"\"\"\n",
    "\n",
    "tractography.add_nodes([bedpostx, flirt])\n",
    "tractography.connect([(bedpostx, probtrackx,\n",
    "                       [('outputnode.thsamples',\n",
    "                         'thsamples'), ('outputnode.phsamples', 'phsamples'),\n",
    "                        ('outputnode.fsamples', 'fsamples')]),\n",
    "                      (probtrackx, findthebiggest, [('targets', 'in_files')]),\n",
    "                      (flirt, probtrackx, [('out_matrix_file', 'xfm')])])\n",
    "\"\"\"\n",
    "Setup data storage area\n",
    "\"\"\"\n",
    "\n",
    "datasink = pe.Node(interface=nio.DataSink(), name='datasink')\n",
    "datasink.inputs.base_directory = os.path.abspath('dtiresults')\n",
    "\n",
    "\n",
    "def getstripdir(subject_id):\n",
    "    import os\n",
    "    return os.path.join(\n",
    "        os.path.abspath('data/workingdir/dwiproc'),\n",
    "        '_subject_id_%s' % subject_id)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Setup the pipeline that combines the 2 workflows: tractography & computeTensor\n",
    "------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "dwiproc = pe.Workflow(name=\"dwiproc\")\n",
    "dwiproc.base_dir = os.path.abspath('fsl_dti_tutorial')\n",
    "dwiproc.connect(\n",
    "    [(infosource, datasource, [('subject_id', 'subject_id')]),\n",
    "     (datasource, computeTensor,\n",
    "      [('dwi', 'fslroi.in_file'), ('bvals', 'dtifit.bvals'),\n",
    "       ('bvecs', 'dtifit.bvecs'), ('dwi', 'eddycorrect.inputnode.in_file')]),\n",
    "     (datasource, tractography,\n",
    "      [('bvals', 'bedpostx.inputnode.bvals'),\n",
    "       ('bvecs', 'bedpostx.inputnode.bvecs'), ('seed_file', 'probtrackx.seed'),\n",
    "       ('target_masks', 'probtrackx.target_masks')]),\n",
    "     (computeTensor, tractography,\n",
    "      [('eddycorrect.outputnode.eddy_corrected', 'bedpostx.inputnode.dwi'),\n",
    "       ('bet.mask_file', 'bedpostx.inputnode.mask'), ('bet.mask_file',\n",
    "                                                      'probtrackx.mask'),\n",
    "       ('fslroi.roi_file', 'flirt.reference')]), (infosource, datasink, [\n",
    "           ('subject_id', 'container'), (('subject_id', getstripdir),\n",
    "                                         'strip_dir')\n",
    "       ]), (tractography, datasink, [('findthebiggest.out_file',\n",
    "                                      'fbiggest.@biggestsegmentation')])])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dwiproc.run()\n",
    "    dwiproc.write_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "\"\"\"\n",
    "This is the ehecht DATA Set\n",
    "===============\n",
    "dMRI [DTI, FSL]\n",
    "===============\n",
    "This pipeline example that uses several interfaces to perform analysis on\n",
    "diffusion weighted images using FSL FDT tools.\n",
    "\n",
    "I stripped out the bedpostX generation part and modified the dti_dti_datasource\n",
    "to point directory to a bedpostX directory\n",
    "\"\"\"\n",
    "import nipype.interfaces.io as nio           # Data i/o\n",
    "import nipype.interfaces.fsl as fsl          # fsl\n",
    "import nipype.interfaces.utility as util     # utility\n",
    "import nipype.pipeline.engine as pe          # pypeline engine\n",
    "import os                                    # system functions\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "fsl.FSLCommand.set_default_output_type('NIFTI_GZ')\n",
    "\n",
    "RAWDATAPATH='/GLOBAL_SCRATCH/ERIN_TEST_DATA/Stout_Human/'\n",
    "WORKINGDATAPATH='/GLOBAL_SCRATCH/ERIN_TEST_DATA/STOUT_WD/'\n",
    "\n",
    "### Could also simply autodetect this from the path...\n",
    "subject_list = ['Subj01_Scan1','Subj01_Scan2','Subj01_Scan3', 'Subj02_Scan1', 'Subj02_Scan2a', \\\n",
    "'Subj02_Scan2b', 'Subj03_Scan1',  'Subj03_Scan2a', 'Subj03_Scan2b', 'Subj03_Scan3', 'Subj04_Scan1', \\\n",
    "'Subj05_Scan1', 'Subj05_Scan2', 'Subj05_Scan3', 'Subj06_Scan1', 'Subj06_Scan2a',  'Subj06_Scan2b' ]\n",
    "\n",
    "\n",
    "subj_list = [ x for x in os.listdir(RAWDATAPATH) if 'Subj' in x ]\n",
    "subject_list = subj_list  ### building a larger subject list\n",
    "\n",
    "\"\"\"\n",
    "Setting up workflows\n",
    "--------------------\n",
    "This is a generic workflow for DTI data analysis using the that I have adapted for  Ehecht Stout\n",
    "\"\"\"\n",
    "print len(subject_list),\"entries to process\"\n",
    "\n",
    "\"\"\"\n",
    "Map field names to individual subject runs\n",
    "\"\"\"\n",
    "\n",
    "infosource = pe.Node(interface=util.IdentityInterface(fields=['subject_id']),    name=\"infosource\")\n",
    "infosource.iterables = ('subject_id', subject_list)\n",
    "### Above just converts the list of subjects into an iterable list I can connect to the next part of the pipeline\n",
    "\n",
    "info = dict(\n",
    "             bvecs = [['subject_id','bvecs']],\n",
    "            bvals = [['subject_id','bvals']],\n",
    "             thsamples = [['subject_id','th1samples']],\n",
    "             phsamples =  [['subject_id','ph1samples']],\n",
    "             fsamples =  [['subject_id','f1samples']]   ,\n",
    "             nodif_brain_mask = [['subject_id','nodif_brain_mask']],\n",
    "             nodif_to_struct_aff =   [['subject_id','nodif_12dof_struc.mat']],\n",
    "\t     struct_warpto_MNI = [['subject_id', 'struc_warp_MNI_warpfield.nii.gz']],\n",
    "\t     struct_to_nodif_aff = [['subject_id','struc_12dof_nodif.mat']],\n",
    "             MNI_to_struct = [['subject_id','MNI_warp_struc_warpfield.nii.gz']]\n",
    "                                 )\n",
    "\n",
    "#             seed_region_base_dir = [['subject_id']],\n",
    "##             xfm_base_dir = [['subject_id']],\n",
    "\n",
    "### Generate the files/names for the DTI/bedpostX data\n",
    "dti_datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'], outfields=info.keys() ),   name='dti_datasource')\n",
    "dti_datasource.inputs.base_directory = RAWDATAPATH\n",
    "dti_datasource.inputs.template = \"*\"\n",
    "dti_datasource.inputs.sort_filelist=True\n",
    "dti_datasource.inputs.field_template = dict( nodif_brain_mask = '%s/DTI/data/%s.nii.gz',\n",
    "        bvecs='%s/DTI/data/%s', bvals='%s/DTI/data/%s',  \n",
    "  thsamples='%s/DTI/data.bedpostX/merged_%s.nii.gz', phsamples='%s/DTI/data.bedpostX/merged_%s.nii.gz',\n",
    "  fsamples='%s/DTI/data.bedpostX/merged_%s.nii.gz', nodif_to_struct_aff = '%s/xfms/%s', \n",
    "\t\tstruct_warpto_MNI='%s/xfms/%s', struct_to_nodif_aff='%s/xfms/%s', MNI_to_struct='%s/xfms/%s'\n",
    "     )\n",
    "dti_datasource.inputs.template_args = info\n",
    "\n",
    "# roi_datasource = pe.Node(interface=nio.DataGrabber(infields=['subject_id'],outfields = ['seed_rois'],  name='roi_datasource')\n",
    "# roi_datasource.inputs.base_directory = RAWDATAPATH\n",
    "# roi_datasource.inputs.template = \"*\"\n",
    "# roi_datasource.inputs.field_template = {'seed_rois': '%s/ROIs/warped_ROIs_in_cropped_struct_space/Bar*.nii.gz'   }\n",
    "# roi_datasource.inputs.template_args = {'seed_rois': [['subject_id']] }\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Setup for Tracktography\n",
    "-----------------------\n",
    "Here we will create a generic workflow for DTI computation, this workflow assumes the .bedpostX has already been run...\n",
    "Here we will create a workflow to enable probabilistic tracktography and hard segmentation of the seed region\n",
    "\"\"\"\n",
    "stout_tractography = pe.Workflow(name='stout_tractography')\n",
    "stout_tractography.base_dir = WORKINGDATAPATH\n",
    "\n",
    "### First connect the subject list to the workflow to build up the patient lists\n",
    "stout_tractography.connect( infosource,'subject_id',dti_datasource, 'subject_id' )\n",
    "\n",
    "### GENERATE THE WARP FIELDS\n",
    "cvtwarp_mni_to_dti = pe.Node(interface=fsl.ConvertWarp(),name='cvtwarp_mni_to_dti' )\n",
    "cvtwarp_mni_to_dti.inputs.reference = os.path.join(RAWDATAPATH,\"MNI152_T1_1mm_brain.nii.gz\")\n",
    "\n",
    "stout_tractography.connect( dti_datasource, 'nodif_to_struct_aff', cvtwarp_mni_to_dti, 'premat')\n",
    "stout_tractography.connect( dti_datasource, 'struct_warpto_MNI', cvtwarp_mni_to_dti, 'warp1')\n",
    "\n",
    "# $statement .= \" --premat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "# $statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "# $statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc_warp_MNI_warpfield.nii.gz \";\n",
    "\n",
    "cvtwarp_dti_to_mni = pe.Node(interface=fsl.ConvertWarp(),name='cvtwarp_dti_to_mni'  )\n",
    "stout_tractography.connect( dti_datasource, 'nodif_brain_mask', cvtwarp_dti_to_mni, 'reference')\n",
    "stout_tractography.connect( dti_datasource, 'MNI_to_struct', cvtwarp_dti_to_mni, 'warp1')\n",
    "stout_tractography.connect( dti_datasource, 'struct_to_nodif_aff', cvtwarp_dti_to_mni, 'postmat')\n",
    "\n",
    "# $statement .= \" --ref=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "# $statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_warpfield.nii.gz \";\n",
    "# $statement .= \" --postmat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_nodif.mat \";\n",
    "# $statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_12dof_nodif_warpfield.nii.gz \";\n",
    "\n",
    "#PERFORM PROBALISTIC TRACTOGRAPHY\n",
    "\n",
    "pbx2 = pe.Node(interface=fsl.ProbTrackX2(),name='pbx2')\n",
    "pbx2.inputs.c_thresh = 0.2\n",
    "pbx2.inputs.n_steps=2000\n",
    "pbx2.inputs.step_length=0.5\n",
    "pbx2.inputs.n_samples= 5000 ### Make n_samples an iterable field...\n",
    "pbx2.inputs.opd=True\n",
    "pbx2.inputs.loop_check=True\n",
    "pbx2.inputs.omatrix2=True  ##This requires I include target2\n",
    "pbx2.inputs.correct_path_distribution=True ##corresponds to the --pd flag\n",
    "pbx2.inputs.onewaycondition=True  \n",
    "pbx2.inputs.target2= os.path.join(RAWDATAPATH,\"MNI152_T1_1mm_brain_mask_downsample_2.nii.gz\")\n",
    "pbx2.inputs.rand_fib=0\n",
    "\n",
    "### This will eventually become an iterable\n",
    "pbx2.inputs.seed= [os.path.join(RAWDATAPATH,\"ROIs/Human_IFG-vPrCG_L.nii.gz\"),os.path.join(RAWDATAPATH,\"ROIs/Human_IFG-vPrCG_R.nii.gz\")]\n",
    "\n",
    "\n",
    "# roi_list = [x for x in os.path.join(RAWDATAPATH,\"ROIs/Human_*/*.nio.gz\")]\n",
    "\n",
    "# $statement  = \" probtrackx2 --pd --onewaycondition --omatrix2 \";\n",
    "# $statement .= \" -s $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data.bedpostX/merged \"; \n",
    "# $statement .= \" -m $WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "# $statement .= \" -x $WORKINGDATAPATH/ROIs/Human_\" . $roi[$r] . \"_\" . $hemi[$h] . \".nii.gz \";\n",
    "# $statement .= \" --target2=$WORKINGDATAPATH/MNI152_T1_1mm_brain_mask_downsample_2.nii.gz \";\n",
    "# $statement .= \" -l -c 0.2 -S 2000 --steplength=0.5 -P 5000 --fibthresh=0.1 --randfib=0 \";  # check samples \n",
    "# $statement .= \" --xfm=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_12dof_nodif_warpfield.nii.gz \";\n",
    "# $statement .= \" --invxfm=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc_warp_MNI_warpfield.nii.gz \";\n",
    "# $statement .= \" --forcedir --opd \";\n",
    "# $statement .= \" --dir=$OUTPUTDATAPATH/\" . $subj[$i] . \"_\" . $roi[$r] . \"_\" . $hemi[$h] . \"_Segmentation  \";\n",
    "\n",
    "stout_tractography.connect( dti_datasource,'thsamples',pbx2,'thsamples')\n",
    "stout_tractography.connect( dti_datasource,'phsamples',pbx2,'phsamples')\n",
    "stout_tractography.connect( dti_datasource,'fsamples',pbx2,'fsamples')\n",
    "stout_tractography.connect( dti_datasource,'nodif_brain_mask',pbx2,'mask')\n",
    "\n",
    "### Now connect the warps generated from the previous steps\n",
    "\n",
    "stout_tractography.connect( cvtwarp_dti_to_mni, 'out_file',pbx2,'xfm')\n",
    "stout_tractography.connect( cvtwarp_mni_to_dti, 'out_file',pbx2,'inv_xfm')\n",
    "\n",
    "# preuss_tractography.connect( roi_datasource, 'seed_rois',probtrackx,'seed')\n",
    "#preuss_tractography.connect( seed_mask_ds,'out_files',probtrackx,'seed')\n",
    "#preuss_tractography.connect( dti_dti_datasource, ('subject_id',mask_info),probtrackx,'seed')\n",
    "\n",
    "\"\"\"\n",
    "Setup data storage area for results\n",
    "\"\"\"\n",
    "datasink = pe.Node(interface=nio.DataSink(),name='datasink')\n",
    "\n",
    "stout_tractography.connect( pbx2, 'fdt_paths', datasink, 'fdt_paths')\n",
    "stout_tractography.connect( pbx2, 'matrix1_dot', datasink, 'matrix1.txt')\n",
    "stout_tractography.connect( pbx2, 'matrix2_dot', datasink, 'matrix2.txt')\n",
    "stout_tractography.connect( pbx2, 'matrix3_dot', datasink, 'matrix3.txt')\n",
    "stout_tractography.connect( pbx2, 'lookup_tractspace', datasink, 'lookup_ts')\n",
    "stout_tractography.connect( pbx2, 'way_total', datasink, 'waytotal.txt')\n",
    "\n",
    "\n",
    "#datasink.inputs.base_directory = put_cleaned_up_results_here\n",
    "#datasink.inputs.substitutions = [('_subject_id_', ''),\n",
    "#                                 ('_seed_..bigdata2..NIPYPE_WD..SANCHEZ_WD..', '')]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    stout_tractography.write_graph(format='eps')\n",
    "    #stout_tractography.export_graph()\n",
    "    # stout_tractography.run(plugin='MultiProc', plugin_args={'n_procs': 28})\n",
    "    #dwiproc.run(plugin='PBS', plugin_args = dict(qsub_args='-k oe -q batch ') )\n",
    "    stout_tractography.run(plugin='PBS', plugin_args=dict(qsub_args='-e trq_logs -o trq_logs -q batch '))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "###WORKINGDATAPATH\n",
    "\n",
    "# $statement  = \" convertwarp \";\n",
    "# $statement .= \" --ref=$WORKINGDATAPATH/MNI152_T1_1mm_brain.nii.gz \";\n",
    "# $statement .= \" --premat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc.mat \";\n",
    "# $statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_warp_MNI_warpfield.nii.gz \";\n",
    "# $statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/nodif_12dof_struc_warp_MNI_warpfield.nii.gz \";\n",
    "# print \"$statement \\n\";\n",
    "\n",
    "# $statement  = \" convertwarp \";\n",
    "# $statement .= \" --ref=$WORKINGDATAPATH/\" . $subj[$i] . \"/DTI/data/nodif_brain_mask.nii.gz \";\n",
    "# $statement .= \" --warp1=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_warpfield.nii.gz \";\n",
    "# $statement .= \" --postmat=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/struc_12dof_nodif.mat \";\n",
    "# $statement .= \" --out=$WORKINGDATAPATH/\" . $subj[$i] . \"/xfms/MNI_warp_struc_12dof_nodif_warpfield.nii.gz \";\n",
    "# print \"$statement \\n\";\n",
    "\n",
    "# print \"$statement \\n\";\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
